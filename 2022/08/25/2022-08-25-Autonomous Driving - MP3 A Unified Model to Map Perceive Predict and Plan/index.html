<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"txing-casia.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="MP3: A Unified Model to Map, Perceive, Predict and Plan (Uber ATG, 2021)  HD map具有的语义和几何信息使其成为自动驾驶系统的关键部件。但HD map的成本很高，难扩展，尤其是厘米级精度（centimeter-level accuracy）的情况下。因此能摆脱HD Map（地图加载失败、地图老旧等）的算法值得研">
<meta property="og:type" content="article">
<meta property="og:title" content="Autonomous Driving | MP3 A Unified Model to Map Perceive Predict and Plan (Uber ATG 2021)">
<meta property="og:url" content="https://txing-casia.github.io/2022/08/25/2022-08-25-Autonomous%20Driving%20-%20MP3%20A%20Unified%20Model%20to%20Map%20Perceive%20Predict%20and%20Plan/index.html">
<meta property="og:site_name" content="Txing">
<meta property="og:description" content="MP3: A Unified Model to Map, Perceive, Predict and Plan (Uber ATG, 2021)  HD map具有的语义和几何信息使其成为自动驾驶系统的关键部件。但HD map的成本很高，难扩展，尤其是厘米级精度（centimeter-level accuracy）的情况下。因此能摆脱HD Map（地图加载失败、地图老旧等）的算法值得研">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-08-24T16:00:00.000Z">
<meta property="article:modified_time" content="2023-03-25T01:54:15.019Z">
<meta property="article:author" content="Txing">
<meta property="article:tag" content="Imitation Learning">
<meta property="article:tag" content="Autonomous Driving">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://txing-casia.github.io/2022/08/25/2022-08-25-Autonomous%20Driving%20-%20MP3%20A%20Unified%20Model%20to%20Map%20Perceive%20Predict%20and%20Plan/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Autonomous Driving | MP3 A Unified Model to Map Perceive Predict and Plan (Uber ATG 2021) | Txing</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Txing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">欢迎来到 | 伽蓝之堂</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/08/25/2022-08-25-Autonomous%20Driving%20-%20MP3%20A%20Unified%20Model%20to%20Map%20Perceive%20Predict%20and%20Plan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/my_photo.jpg">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用人形决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Autonomous Driving | MP3 A Unified Model to Map Perceive Predict and Plan (Uber ATG 2021)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-08-25 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-25T00:00:00+08:00">2022-08-25</time>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>8.5k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>8 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2
id="mp3-a-unified-model-to-map-perceive-predict-and-plan-uber-atg-2021">MP3:
A Unified Model to Map, Perceive, Predict and Plan (Uber ATG, 2021)</h2>
<ul>
<li>HD map具有的语义和几何信息使其成为自动驾驶系统的关键部件。但HD
map的成本很高，难扩展，尤其是厘米级精度（centimeter-level
accuracy）的情况下。因此能摆脱HD
Map（地图加载失败、地图老旧等）的算法值得研究。本文提出了一种<strong>end2end</strong>的<strong>不依赖地图</strong>的自动驾驶算法——MP3。</li>
<li>输入为：
<ul>
<li><strong>raw sensor data</strong></li>
<li><strong>high-level command</strong> (e.g., turn left at the
intersection)</li>
</ul></li>
<li>本文的定位为：mapless technology 的自动驾驶</li>
</ul>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li><p>没有HD map的劣势：</p>
<ul>
<li><p>感知不能再依赖“人行道上的行人”、“道路上的车辆”这样的先验信息；</p></li>
<li><p>进行规划的空间变大了</p></li>
</ul></li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-1.png"
alt="有地图和无地图对比" />
<figcaption aria-hidden="true">有地图和无地图对比</figcaption>
</figure>
<ul>
<li>车辆需要把到达抽象成为路口直行（going straight at an
intersection）、左转（turning left）和右转（turning
right）等高阶的行为指令。</li>
<li>大多数的无地图方法模仿专家的驾驶行为（朝向角、加速度），但是没有提供可解释的中间表征（intermediate
interpretable representations），而这可以帮助解释车辆的决策行为
<ul>
<li>End to end learning for self-driving cars. arXiv preprint
arXiv:1604.07316, 2016.</li>
<li>End-to-end driving via conditional imitation learning. In ICRA,
2018.</li>
<li>Urban driving with conditional imitation learning. arXiv preprint
arXiv:1912.00177, 2019.</li>
<li>Lift, splat, shoot: Encoding images from arbitrary camera rigs by
implicitly unprojecting to 3d. In Proceedings of the European Conference
on Computer Vision, 2020.</li>
</ul></li>
<li>这些方法没有结构信息和先验知识，容易受到分布漂移（distributional
shift）的影响
<ul>
<li>A reduction of imitation learning and structured prediction to
no-regret online learning. In Proceedings of the fourteenth
international conference on artificial intelligence and statistics,
pages 627–635, 2011.</li>
</ul></li>
<li>一些使用在线地图的方法（获得道路边界、中心线），要么过度简单（假设了车道是平行的，但这只在高速场景适用），要么难以将静态环境的不确定性纳入运动规划，而运动规划对于降低风险至关重要。[2,
16, 18, 21, 37],
<ul>
<li>Deep multi-sensor lane detection. In IROS, pages 3102–3109. IEEE,
2018.</li>
<li>3d-lanenet: End-to-end 3d multiple lane detection. In Proceedings of
the IEEE International Conference on Computer Vision, pages 2921–2930,
2019.</li>
<li>Gen-lanenet: A generalized and scalable approach for 3d lane
detection. arXiv, pages arXiv–2003, 2020.</li>
<li>Hierarchical recurrent attention networks for structured online
maps. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 3417–3426, 2018.</li>
</ul></li>
</ul>
<h3 id="related-work">2 Related Work</h3>
<h4 id="online-mapping">2.1 Online Mapping:</h4>
<ul>
<li>特点：
<ul>
<li>satellite imagery (卫星图像)</li>
<li>gather dense information (采集车多次经过同一地方)</li>
<li>human-in-the-loop</li>
</ul></li>
<li>predicting map elements online:
<ul>
<li>3d-lanenet: End-to-end 3d multiple lane detection. In Proceedings of
the IEEE International Conference on Computer Vision, pages 2921–2930,
2019.</li>
<li>Gen-lanenet: A generalized and scalable approach for 3d lane
detection. arXiv, pages arXiv–2003, 2020.</li>
</ul></li>
</ul>
<h4 id="perception-and-prediction">2.2 Perception and Prediction</h4>
<ul>
<li><strong>生成轨迹集合</strong> generate a fixed set of trajectories
[6, 8–10, 26, 28, 30, 36, 56]</li>
<li><strong>画出样本特征分布</strong> draw samples to characterize the
distribution
<ul>
<li>Implicit latent variable model for scene-consistent motion
forecasting. arXiv preprint arXiv:2007.12036, 2020.</li>
<li>R2p2: A reparameterized pushforward policy for diverse, precise
generative path forecasting. In ECCV, 2018.</li>
<li>Multiple futures prediction. In Advances in Neural Information
Processing Systems, pages 15398–15408, 2019.</li>
</ul></li>
<li><strong>预测时间占用图</strong> predict temporal occupancy maps
<ul>
<li>Discrete residual flow for probabilistic pedestrian behavior
prediction. arXiv preprint arXiv:1910.08041, 2019.</li>
<li>The garden of forking paths: Towards multi-future trajectory
prediction. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 10508–10518, 2020.</li>
<li>Scene compliant trajectory forecast with agent-centric
spatio-temporal grids. IEEE RA-L, 5(2):2816–2823, 2020.</li>
</ul></li>
<li>这些方法由于涉及了非最大抑制（non-maximum
suppression）和可信度阈值（confidence
thresholding），可能出现不安全的情况</li>
<li>occupancy grids:
<ul>
<li>Motionnet: Joint perception and motion prediction for autonomous
driving based on bird’s eye view maps. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages
11385–11395, 2020.</li>
<li>Learning occupancy grid maps with forward sensor models. Autonomous
robots, 15(2):111–127, 2003.</li>
<li><strong>Perceive, predict, and plan: Safe motion planning through
interpretable semantic representations.</strong> In Proceedings of the
European Conference on Computer Vision (ECCV), 2020.</li>
</ul></li>
</ul>
<h4 id="motion-planning">2.3 Motion Planning</h4>
<ul>
<li>从感知直接输出控制信号 （Driving policy transfer via modularity and
abstraction. arXiv preprint arXiv:1804.09364,
2018.）会面临稳定性和鲁棒性的问题（stability and robustness
issues）（Exploring the limitations of behavior cloning for autonomous
driving. In Proceedings of the IEEE International Conference on Computer
Vision, pages 9329–9338, 2019.）</li>
</ul>
<h3 id="interpretable-mapless-driving">3 Interpretable Mapless
Driving</h3>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-2.png"
alt="MP3 predicts probabilistic scene representations that are leveraged in motion planning as interpretable cost functions" />
<figcaption aria-hidden="true">MP3 predicts probabilistic scene
representations that are leveraged in motion planning as interpretable
cost functions</figcaption>
</figure>
<h4 id="extracting-geometric-and-semantic-features">3.1 Extracting
Geometric and Semantic Features</h4>
<ul>
<li>The result is a 3D tensor of size <span
class="math display">\[(\frac{H}{a},\frac{W}{a},\frac{Z}{a}\cdot T_p
)\]</span>,which is the input to our backbone network.</li>
<li>This network combines ideas from [9, 53] to extract geometric,
semantic and motion information about the scene.</li>
</ul>
<h4 id="interpretable-scene-representations">3.2 Interpretable Scene
Representations</h4>
<ul>
<li>道路先验信息和一些可解释的知识，使用 <code>online map</code>
表示</li>
<li>动态目标的位置、速度信息，使用 <code>dynamic occupancy field</code>
表示（the dynamic objects position and velocity into the future,
captured in our dynamic occupancy field）</li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-3.png"
alt="Interpretable Scene representations" />
<figcaption aria-hidden="true">Interpretable Scene
representations</figcaption>
</figure>
<ul>
<li>具体而言，两种表征信息包括：</li>
</ul>
<p><strong>Online map representation:</strong></p>
<ul>
<li>Drivable area：以道路边缘为界的可行驶区域；</li>
<li>Reachable
lanes：可用车道是SDV在不违反任何交通规则的情况下可以到达的运动路径的子集。规划轨迹时，我们希望SDV靠近这些可到达的车道，并按照它们的方向行驶。因此，对于地平面中的每个像素，我们预测到最近的可到达车道中心线的无符号距离，在10米处截断，以及最近的可到达车道中心线分段的角度。</li>
<li>Intersection：被交通信号等或者交通标志控制的路段，需要根据信号灯或者标志按交通规定行驶；</li>
</ul>
<p><strong>Dynamic occupancy field:</strong></p>
<p>现有的行为预测算法包括不安全的离散决策unsafe discrete decisions such
as confidence thresholding and non-maximum suppression (NMS)</p>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-4.png"
alt="The motion field warps the occupancy over time" />
<figcaption aria-hidden="true">The motion field warps the occupancy over
time</figcaption>
</figure>
<ul>
<li>Initial Occupancy：一个BEV网格单元</li>
<li>Temporal Motion Field：a 2D BEV velocity vector (in m/s).</li>
<li><code>Note</code>：车辆、行人和自行车被视为单独的类别，每个类别都有自己的占用流。</li>
</ul>
<p><strong>Probabilistic Model:</strong></p>
<p>online Map 分为以下几个通道：</p>
<ul>
<li><p>可到达区域<span class="math display">\[M^A_i\]</span></p></li>
<li><p>路口<span class="math display">\[M^I_i\]</span></p></li>
<li><p>到最近车道线的距离。the direction of the closest lane centerline
in the reachable lanes <span
class="math display">\[M^{\theta}_i\]</span> as a Von Mises distribution
since it has support between <span
class="math display">\[[\pi,\pi]\]</span>.</p></li>
<li><p>可到达车道中线的截断距离变换为拉普拉斯算子。We model the
truncated distance transform to the reachable lanes centerline <span
class="math display">\[M^D_i\]</span>​ as a Laplacian, which we
empirically found to yield more accurate results than a
Gaussian</p></li>
</ul>
<p>建模动态物体的occupancy <span
class="math display">\[O^c\]</span>,为伯努利随机分布<span
class="math display">\[O^c_{t,i}\]</span>，<span
class="math display">\[c\in
\{行人，车辆，自行车\}\]</span>（考虑这些物体未来行为的多模态（直走或左转）和不确定性），用<span
class="math display">\[K_{t,i}\]</span>建模基于K个BEV运动向量<span
class="math display">\[V^c_{t,i,k}\]</span>的行为分类分布</p>
<p>the probability of future occupancy under our probabilistic model, we
first define the probability of occupancy flowing from location <span
class="math display">\[i_1\]</span> to location <span
class="math display">\[i_2\]</span> between two consecutive time steps t
and t + 1 as follows:</p>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220829-1.png"
alt="the probability of occupancy flowing" />
<figcaption aria-hidden="true">the probability of occupancy
flowing</figcaption>
</figure>
<h4 id="motion-planning-1">3.3 Motion Planning</h4>
<p>设计了一个基于采样的轨迹规划器，其根据运动学灵活的生成多种轨迹，然后使用一个learned
scoring function选择轨迹。</p>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220830-1.png"
alt="规划器的轨迹选择方式" />
<figcaption aria-hidden="true">规划器的轨迹选择方式</figcaption>
</figure>
<h5 id="trajectory-sampling">3.3.1 Trajectory Sampling</h5>
<p>Search-based optimal motion planning for automated driving. In IROS,
2018</p>
<ul>
<li>根据<span
class="math display">\[(v_x,a_x,k_x)\]</span>在专家轨迹数据集中检索专家轨迹，<span
class="math display">\[x\]</span>表示当前自车状态，检索出的轨迹有不同的初始速度和朝向。因此使用加速度和转向角来描述轨迹<span
class="math display">\[(a,\dot k)_t,t=0,...,T\]</span>，输入到a bicycle
model [38]生成具有连续速度和转向角的轨迹。
<ul>
<li>[38]. The kinematic bicycle model: A consistent model for planning
feasible trajectories for autonomous vehicles? In 2017 IEEE Intelligent
Vehicles Symposium (IV), pages 812–818. IEEE, 2017.</li>
</ul></li>
<li>文献[37]提供了一个忽略自车初始状态的简化的轨迹生成模型。
<ul>
<li>[37]. Lift, splat, shoot: Encoding images from arbitrary camera rigs
by implicitly unprojecting to 3d. In Proceedings of the European
Conference on Computer Vision, 2020.</li>
</ul></li>
</ul>
<h5 id="route-prediction">3.3.2 Route Prediction</h5>
<ul>
<li>由于无地图驾驶没有车道线follow，本文假设遵循command来行驶，指令<span
class="math display">\[c = (a, d)\]</span>, where <span
class="math display">\[a \in \{keep lane, turn left, turn
right\}\]</span> is a discrete high-level action, and <span
class="math display">\[d\]</span> an approximate longitudinal distance
to the
action（行为的纵向距离）（d经过”rasterize”处理），输入给CoordConv[29]
<ul>
<li>An intriguing failing of convolutional neural networks and the
coordconv solution. In Advances in Neural Information Processing
Systems, pages 9605–9616, 2018.</li>
</ul></li>
</ul>
<h5 id="trajectory-scoring">3.3.2 Trajectory Scoring</h5>
<ul>
<li>Routing and Driving on Roads:
该评分函数鼓励车辆行驶在概率图R中概率高的区域</li>
</ul>
<p><span class="math display">\[
f_r(\tau,R)=-m(\tau)\min_{i \in m(\tau)} R_i
\]</span></p>
<p>其中<span
class="math display">\[m(\tau)\]</span>是BEV图中和自车轨迹<span
class="math display">\[\tau\]</span>重合的格子单元（grid-cells that
overlap with SDV polygon in trajectory <span
class="math display">\[\tau\]</span>)</p>
<p>离开车道损失： <span class="math display">\[
f_a(x,M)=\max_{i \in m(x)}[1-P(M_i^A)]
\]</span></p>
<ul>
<li><p>Safety</p></li>
<li><p>Comfort</p>
<p>惩罚jerk和加速度</p></li>
</ul>
<h4 id="learning">3.4. Learning</h4>
<p>两阶段的训练。我们分两个阶段优化我们的驾驶模型。我们首先训练<strong>online
map</strong>、<strong>dynamic occupancy
field</strong>和<strong>routing</strong>。一旦这些被收敛，在第二阶段，我们保持这些部分冻结，并为得分函数的线性组合训练规划器权重。我们发现这种两阶段的培训比端到端的培训更稳定。（We
optimize our driving model in two stages. We first train the online map,
dynamic occupancy field, and routing. Once these are converged, in a
second stage, we keep these parts frozen and train the planner weights
for the linear combination of scoring functions. We found this 2-stage
training empirically more stable than training end-to-end.）</p>
<h3 id="experimental-evaluation">4. Experimental Evaluation</h3>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-1.png"
alt="性能指标" />
<figcaption aria-hidden="true">性能指标</figcaption>
</figure>
<ul>
<li>Imitation Learning (IL), where the future positions of the SDV are
predicted directly from the scene context features, and is trained using
L2 loss.</li>
<li>Conditional Imitation Learning (CIL) [11], which is similar to IL
but the trajectory is conditioned on the driving command.
<ul>
<li>End-to-end driving via conditional imitation learning. In ICRA,
2018.</li>
</ul></li>
<li>Neural Motion Planner (NMP) [55], where a planning cost-volume as
well as detection and prediction are predicted in a multi-task fashion
from the scene context features, and Trajectory Classification (TC)
[37], where a cost-volume is predicted similar to NMP, but the
trajectory cost is used to create a probability distribution over the
trajectories and is trained by optimizing for the likelihood of the
expert trajectory.
<ul>
<li>Lift, splat, shoot: Encoding images from arbitrary camera rigs by
implicitly unprojecting to 3d. In Proceedings of the European Conference
on Computer Vision, 2020.</li>
<li>End-to-end interpretable neural motion planner. In CVPR, 2019.</li>
</ul></li>
<li>Finally, we extend NMP to consider the high-level command by
learning a separate costing network for each discrete action
(CNMP).</li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-2.png"
alt="Backbone Network" />
<figcaption aria-hidden="true">Backbone Network</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-3.png"
alt="Mapping Network" />
<figcaption aria-hidden="true">Mapping Network</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-4.png"
alt="Perception and Prediction Network" />
<figcaption aria-hidden="true">Perception and Prediction
Network</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-5.png"
alt="Routing Network" />
<figcaption aria-hidden="true">Routing Network</figcaption>
</figure>
<figure>
<img
src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-6.png"
alt="Sets of trajectories retrieved from the expert demonstrations." />
<figcaption aria-hidden="true">Sets of trajectories retrieved from the
expert demonstrations.</figcaption>
</figure>
<p>后面还有大量实验情景的展示图。</p>
<h3 id="总结">总结</h3>
<p>比较有想法的一个工作，做得比较细致，但是介绍相对粗略，可以仔细研究。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Imitation-Learning/" rel="tag"># Imitation Learning</a>
              <a href="/tags/Autonomous-Driving/" rel="tag"># Autonomous Driving</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/08/24/2022-08-24-Autonomous%20Driving%20-%20On%20the%20Choice%20of%20Data%20for%20Efficient%20Training%20and%20Validation%20of%20End-to-End%20Driving%20Models/" rel="prev" title="Autonomous Driving | On the Choice of Data for Efficient Training and Validation of End-to-End Driving Models">
      <i class="fa fa-chevron-left"></i> Autonomous Driving | On the Choice of Data for Efficient Training and Validation of End-to-End Driving Models
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/05/2022-09-05%20-%20Python%E6%8A%A5%E9%94%99libGL%20error%20MESA-LOADER%20failed%20to%20open%20iris/" rel="next" title="Python报错libGL error: MESA-LOADER: failed to open iris">
      Python报错libGL error: MESA-LOADER: failed to open iris <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#mp3-a-unified-model-to-map-perceive-predict-and-plan-uber-atg-2021"><span class="nav-number">1.</span> <span class="nav-text">MP3:
A Unified Model to Map, Perceive, Predict and Plan (Uber ATG, 2021)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#introduction"><span class="nav-number">1.1.</span> <span class="nav-text">1 Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#related-work"><span class="nav-number">1.2.</span> <span class="nav-text">2 Related Work</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#online-mapping"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Online Mapping:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#perception-and-prediction"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Perception and Prediction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#motion-planning"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.3 Motion Planning</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#interpretable-mapless-driving"><span class="nav-number">1.3.</span> <span class="nav-text">3 Interpretable Mapless
Driving</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#extracting-geometric-and-semantic-features"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1 Extracting
Geometric and Semantic Features</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#interpretable-scene-representations"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2 Interpretable Scene
Representations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#motion-planning-1"><span class="nav-number">1.3.3.</span> <span class="nav-text">3.3 Motion Planning</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#trajectory-sampling"><span class="nav-number">1.3.3.1.</span> <span class="nav-text">3.3.1 Trajectory Sampling</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#route-prediction"><span class="nav-number">1.3.3.2.</span> <span class="nav-text">3.3.2 Route Prediction</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#trajectory-scoring"><span class="nav-number">1.3.3.3.</span> <span class="nav-text">3.3.2 Trajectory Scoring</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#learning"><span class="nav-number">1.3.4.</span> <span class="nav-text">3.4. Learning</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#experimental-evaluation"><span class="nav-number">1.4.</span> <span class="nav-text">4. Experimental Evaluation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.5.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Txing"
      src="/images/my_photo.jpg">
  <p class="site-author-name" itemprop="name">Txing</p>
  <div class="site-description" itemprop="description">泛用人形决战型机器人博士</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">229</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">58</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/txing-casia" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;txing-casia" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://blog.uomi.moe/" title="https:&#x2F;&#x2F;blog.uomi.moe" rel="noopener" target="_blank">驱逐舰患者</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://m.mepai.me/photographyer/u_5a68085ba15aa.html?tdsourcetag=s_pctim_aiomsg" title="https:&#x2F;&#x2F;m.mepai.me&#x2F;photographyer&#x2F;u_5a68085ba15aa.html?tdsourcetag&#x3D;s_pctim_aiomsg" rel="noopener" target="_blank">隐之-INF</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Txing</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">538k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">8:09</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
