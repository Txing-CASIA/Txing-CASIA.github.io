---
layout:     post
title:      "Reinforcement Learning | HIerarchical Reinforcement learning with Off-policy correction (HIRO)"
subtitle:   ""
date:       2020-09-11
author:     "Txing"
header-img: "img/post-bg-py.jpg"
tags:
    - Reinforcement Learning
    - HRL
---

# Data-Efficient Hierarchical Reinforcement Learning  

论文链接：

## 背景

HRL是处理复杂任务的有效方式，之前的方法大多需要针对具体任务进行特殊设计，并使用on-policy的方法进行训练，这些因素导致HRL很难被引用到真实的场景中。本文用off-policy的方式训练higher- and lower-level controllers，提高了模型的数据利用率，性能超过了之前SOTA的Option-Critic。

**Option-Critic**：Pierre-Luc Bacon, Jean Harb, and Doina Precup. The option-critic architecture. In AAAI, pages
1726–1734, 2017.  

## 主要工作











## 总结

文章种在多个游戏中进行了实验对比，均取得了良好的实验效果。但遗憾的是，几乎所有的复现都说性能达不到文章中的水平。可能是实验中还有一些优化并未在文章中说明。







