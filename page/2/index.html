<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"txing-casia.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="泛用类人决战型机器人博士">
<meta property="og:type" content="website">
<meta property="og:title" content="Txing">
<meta property="og:url" content="https://txing-casia.github.io/page/2/index.html">
<meta property="og:site_name" content="Txing">
<meta property="og:description" content="泛用类人决战型机器人博士">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Txing">
<meta property="article:tag" content="Txing">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://txing-casia.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Txing</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Txing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">欢迎来到 | 伽蓝之堂</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/30/2022-09-30-Autonomous%20Driving%20-%20Parallel%20Angular%20and%20Perpendicular%20Parking%20for%20Self-Driving%20Cars%20using%20Deep%20Reinforcement%20Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/30/2022-09-30-Autonomous%20Driving%20-%20Parallel%20Angular%20and%20Perpendicular%20Parking%20for%20Self-Driving%20Cars%20using%20Deep%20Reinforcement%20Learning/" class="post-title-link" itemprop="url">Autonomous Driving | Parallel, Angular and Perpendicular Parking for Self-Driving Cars using Deep Reinforcement Learning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-30 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-30T00:00:00+08:00">2022-09-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="parallel-angular-and-perpendicular-parking-for-self-driving-cars-using-deep-reinforcement-learning">Parallel,
Angular and Perpendicular Parking for Self-Driving Cars using Deep
Reinforcement Learning</h2>
<p>parking是所有驾驶行为的最终步骤，主要分为三类：垂直、平行、斜向泊车。</p>
<p>本文使用DDPG控制汽车完成三种场景的泊车。</p>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li>强化学习控制泊车：
<ul>
<li>"Reinforcement learning-based end-to-end parking for automatic
parking system", Sensors (Switzerland), vol. 19 ,September 2019.</li>
<li>“An Automatic Parking Model Based on Deep Reinforcement Learning",
2021 J. Phys.: Conf. Ser. 1883 012111.</li>
</ul></li>
<li>parallel autonomous parking (truncated Monte Carlo tree):
<ul>
<li>“Data efficient reinforcement learning for integrated lateral
planning and control in automated parking system”, Sensors
(Switzerland), vol. 20, pp. 1–24, dec 2020.</li>
<li>"Reinforcement Learning-Based Motion Planning for Automatic Parking
System," in IEEE Access, vol. 8, pp. 154485-154501, 2020, doi:
0.1109/ACCESS.2020.3017770.</li>
</ul></li>
<li>避障：
<ul>
<li>"Q-Learning for Autonomous Mobile Robot Obstacle Avoidance," 2019
IEEE International Conference on Autonomous Robot Systems and
Competitions (ICARSC), Porto, Portugal, 2019, pp. 1-7. DOI:
10.1109/ICARSC.2019.8733621</li>
<li>Combining YOLO and Deep Reinforcement Learning for Autonomous
Driving in Public Roadworks Scenarios. In Proceedings of the 14th
International Conference on Agents and Artificial Intelligence - Volume
3: ICAART, ISBN 978-989-758-547-0, pages 793-800. DOI:
10.5220/0010913600003116.</li>
</ul></li>
</ul>
<h3 id="总结">总结</h3>
<p>本文除了比较新之外（2022）没有无亮点，完全借用DDPG分别实现三种库的parking</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/30/2022-09-30-Autonomous%20Driving%20-%20From%20smart%20parking%20towards%20autonomous%20valet%20parking%20A%20survey%20challenges%20and%20future%20Works/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/30/2022-09-30-Autonomous%20Driving%20-%20From%20smart%20parking%20towards%20autonomous%20valet%20parking%20A%20survey%20challenges%20and%20future%20Works/" class="post-title-link" itemprop="url">Autonomous Driving | From smart parking towards autonomous valet parking: A survey, challenges and future Works</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-30 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-30T00:00:00+08:00">2022-09-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="from-smart-parking-towards-autonomous-valet-parking-a-survey-challenges-and-future-works">From
smart parking towards autonomous valet parking: A survey, challenges and
future Works</h2>
<p>停车的基本任务要求：</p>
<ul>
<li>找车位 finding the proper parking slot,</li>
<li>提升使用者的体验 increasing users’ experience,</li>
<li>动态的路径规划 dynamic path planning,</li>
<li>避免拥堵 congestion avoidance</li>
</ul>
<p>本综述讨论从智能泊车到自动泊车的技术发展：</p>
<ul>
<li><p>Smart Parking (SP):</p>
<ul>
<li>digitally enhanced parking,</li>
<li>smart routing,</li>
<li>high density parking</li>
<li>vacant slot detection solutions</li>
</ul></li>
<li><p>Autonomous Valet Parking (AVP):</p>
<ul>
<li>Short-range Autonomous Valet Parking (SAVP)</li>
</ul></li>
<li><p>Long-range Autonomous Valet Parking (LAVP)</p></li>
</ul>
<p>这是一篇停车场管理的综述，不是我想找的Autonomous parking算法的。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/29/2022-09-29-Autonomous%20Driving%20-%20Reinforcement%20Learning-Based%20Motion%20Planning%20for%20Automatic%20Parking%20System/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/29/2022-09-29-Autonomous%20Driving%20-%20Reinforcement%20Learning-Based%20Motion%20Planning%20for%20Automatic%20Parking%20System/" class="post-title-link" itemprop="url">Autonomous Driving | Reinforcement Learning-Based Motion Planning for Automatic Parking System</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-29 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-29T00:00:00+08:00">2022-09-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="reinforcement-learning-based-motion-planning-for-automatic-parking-system">Reinforcement
Learning-Based Motion Planning for Automatic Parking System</h2>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li>典型的自动泊车系统包括以下组件：
<ul>
<li>停车位检测 parking slot detection,</li>
<li>运动规划 motion planning (or path planning and tracking),</li>
<li>自我车辆的姿态估计 ego-vehicle’s posture estimation,</li>
<li>底盘控制 chassis control,</li>
</ul></li>
<li>自动泊车算法分类：
<ul>
<li>基于专家驾驶员泊车数据的方法 expert drivers’ parking data-based
method,</li>
<li>基于人类先验知识的方法 human prior knowledge-based method,</li>
<li>基于强化学习的方法 reinforcement learning-based method.</li>
</ul></li>
</ul>
<h4 id="基于专家驾驶员泊车数据的方法">1)
基于专家驾驶员泊车数据的方法</h4>
<ul>
<li>使用监督学习训练神经网络，训练数据需要尽可能覆盖实际使用场景（图像输入）</li>
<li>局限：
<ul>
<li>专家数据是模型的上限；</li>
<li>专家数据难获得；</li>
<li>数据质量要求高；</li>
</ul></li>
</ul>
<h4 id="基于先验知识的方法">2) 基于先验知识的方法</h4>
<ul>
<li><p>abstracting human parking experience into prior knowledge and
then using it to guide the planning.</p></li>
<li><p>几何方法：</p>
<ul>
<li>Reeds-Shepp (RS) curve [6], [7],</li>
<li>clothoid curve [8], [9],</li>
<li>Bezier curve [10],</li>
<li>spline curve [11],</li>
<li>polynomial curve [12]</li>
</ul></li>
<li><p>启发式方法：</p>
<ul>
<li>A* [13]</li>
</ul></li>
<li><p>模糊逻辑方法：</p>
<ul>
<li>fuzzy rules [14], [15]</li>
</ul></li>
</ul>
<h4 id="基于强化学习的方法">3) 基于强化学习的方法</h4>
<ul>
<li><p>前两种方案依赖原始或抽象的人类经验，因此要求高质量的泊车数据。</p></li>
<li><p>可以突破人类数据的限制</p></li>
<li><p>一般认为泊车场景agent比高速场景agent更难训练，因为前者方向盘角度会发生短时间的巨大变化</p></li>
</ul>
<h3 id="总结">总结</h3>
<p>本文质量一般，只看了intro部分，文献较老，没继续看了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/28/2022-09-28-Autonomous%20Driving%20-%20DL-IAPS%20and%20PJSO%20A%20Path%20Speed%20Decoupled%20Trajectory%20Optimization%20and%20its%20Application%20in%20Autonomous%20Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/28/2022-09-28-Autonomous%20Driving%20-%20DL-IAPS%20and%20PJSO%20A%20Path%20Speed%20Decoupled%20Trajectory%20Optimization%20and%20its%20Application%20in%20Autonomous%20Driving/" class="post-title-link" itemprop="url">Autonomous Driving | DL-IAPS and PJSO: A Path/Speed Decoupled Trajectory Optimization and its Application in Autonomous Driving (Baidu, 2020)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-28 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-28T00:00:00+08:00">2022-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="dl-iaps-and-pjso-a-pathspeed-decoupled-trajectory-optimization-and-its-application-in-autonomous-driving">DL-IAPS
and PJSO: A Path/Speed Decoupled Trajectory Optimization and its
Application in Autonomous Driving</h2>
<p>本文是以下三者的结合：</p>
<ul>
<li>collision-free trajectory planning problem</li>
<li>Dual-Loop Iterative Anchoring Path Smoothing (DL-IAPS)</li>
<li>Piece-wise Jerk Speed Optimization (PJSO)</li>
</ul>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li><p>一些环境不支持车辆倒车，但在parking上倒车是必要的，因此需要自由空间轨迹规划算法
Free space trajectory planning algorithm</p></li>
<li><p>当前主流的自由空间轨迹规划方法有两类：</p>
<ul>
<li><strong>路径-速度联合优化方法</strong>（path/speed coupled method）:
Nonlinear Model Predictive Control (NMPC), Mixed Interger Programming
(MIP), Hierarchical Optimization-Based Collision Avoidance
(H-OBCA)。这些方法可以优雅地将车辆动力学和避障结合成一个单一的优化问题，但具有高计算复杂度和低鲁棒性；</li>
<li><strong>路径-速度解耦优化方法</strong>（path/speed decoupled
method）:
先计算平滑路径后计算轨迹轮廓。该方式具有更高的计算效率，但可能不具有控制可行性，在极端情况下无法保证路径或速度的平滑性。</li>
</ul></li>
<li><p><strong>Hybrid A* method: </strong> “Path planning for autonomous
vehicles in unknown semi-structured environments,” The International
Journal of Robotics Research, vol. 29, no. 5, pp. 485–501,
2010.</p></li>
<li><p>迭代曲率约束路径平滑 iterative curvature constrained path
smoothing (i.e., DL-IAPS)</p></li>
<li><p>舒适的最小时间分段加加速度优化 comfortable minimum-time
piece-wise jerk speed optimization (i.e., PJSO)</p></li>
<li><p>主要贡献：</p>
<ul>
<li>精确实时的碰撞避免轨迹生成，Precise Collision Avoidance in
Real-Time，轨迹长度9-14s，检测时间0.18−0.21s</li>
<li>具备可行性的控制，Control Feasibility</li>
<li>兼顾驾驶舒适性和最短行驶时间，Driving comfort and Minimum Traversal
Time</li>
</ul></li>
</ul>
<h3 id="problem-statement">2 Problem Statement</h3>
<ul>
<li>模型包括三部分：
<ul>
<li>Region of Interest (RoI)：感兴趣区域</li>
<li>Trajectory Generation：</li>
<li>Trajectory Post-processing</li>
</ul></li>
</ul>
<h3 id="path-speed-decoupled-trajectory-optimization">3 Path speed
decoupled trajectory optimization</h3>
<h4 id="inner-loop-for-curvature-constrained-path-smoothing">Inner Loop
for Curvature Constrained Path Smoothing:</h4>
<ul>
<li>the nonlinear path smoothing optimization problem is formulated in
as:</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-1.jpg" alt="非线性路径平滑优化问题">
<figcaption aria-hidden="true">非线性路径平滑优化问题</figcaption>
</figure>
<h4 id="outer-loop-for-collision-avoidance">Outer Loop for Collision
Avoidance:</h4>
<ul>
<li>collision check and <span class="math display">\[B_k\]</span>
updates</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-2.jpg" alt="碰撞检测">
<figcaption aria-hidden="true">碰撞检测</figcaption>
</figure>
<h4 id="piece-wise-jerk-speed-optimization">Piece-wise Jerk Speed
Optimization</h4>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-3.jpg" alt="Jerk形式推导">
<figcaption aria-hidden="true">Jerk形式推导</figcaption>
</figure>
<ul>
<li>二次规划优化问题：</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-4.jpg" alt="二次规划优化问题">
<figcaption aria-hidden="true">二次规划优化问题</figcaption>
</figure>
<ul>
<li><p>侧方位停车对比：</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-5.jpg" alt="Optimized path trajectory from starting pose [x = -6m, y = 2.5m, \theta = 0.0] with Hybrid A* path generator and DL-IAPS smoothing">
<figcaption aria-hidden="true">Optimized path trajectory from starting
pose <span class="math display">\[[x = -6m, y = 2.5m, \theta =
0.0]\]</span> with Hybrid A* path generator and DL-IAPS
smoothing</figcaption>
</figure></li>
<li><p>parking 系列实验：</p></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220929-6.jpg" alt="Various simulation test cases with multiple numbers of boundaries and obstacles">
<figcaption aria-hidden="true">Various simulation test cases with
multiple numbers of boundaries and obstacles</figcaption>
</figure>
<h3 id="总结">总结</h3>
<p>整体而言就是在混合A*的基础上，加上了轨迹平滑、碰撞检测、速度规划三个后续模块，在parking任务上取得了一定效果，并集成与Apollo平台中</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/23/2022-09-23-Reinforcement%20Learning%20-%20[u]%20Human-level%20Atari%20200x%20faster/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/23/2022-09-23-Reinforcement%20Learning%20-%20%5Bu%5D%20Human-level%20Atari%20200x%20faster/" class="post-title-link" itemprop="url">Reinforcement Learning | Human-level Atari 200x faster</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-23 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-23T00:00:00+08:00">2022-09-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="human-level-atari-200x-faster-deepmind-2022">Human-level Atari
200x faster (Deepmind, 2022)</h2>
<p>Deepmind的Agent57是第一个在57款Atari游戏上全面超过人类水平的强化学习智能体。但是Agent57的数据利用效率很低，要求80亿帧数据。本文通过设置不同的策略集合实现了200倍的训练效率提高。</p>
<p>4个关键点：</p>
<ul>
<li><p>使用在线网络的近似信赖域的方法，实现稳定的Bootstrapping；</p></li>
<li><p>一个损失和优先级的正则化方案，可在学习具有大范围尺度的价值函数时，提高鲁棒性；</p></li>
<li><p>使用改进的NFNets的架构，不必normalization
layers也可使用深层网络；</p></li>
<li><p>使用策略蒸馏方法，消除瞬时贪婪策略随时间的变化；</p></li>
</ul>
<h3 id="introduction">1 Introduction</h3>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220923-1.png" alt="MEME和Agent57在Atari游戏上达到人类水平所需数据量对比。">
<figcaption aria-hidden="true">MEME和Agent57在Atari游戏上达到人类水平所需数据量对比。</figcaption>
</figure>
<ul>
<li><p>衡量agent学习能力的两种方式：</p>
<ul>
<li><p>在与环境交互有限次后对比性能高低；</p>
<p>但该方法忽略了那些在允许的预算内难以解决的问题；</p></li>
<li><p>对比达到目标性能所需的交互次数；</p>
<p>本文为了和agent57对比，并凸显效率，采用该方式对比；</p></li>
</ul></li>
<li><p>MEME (Efficient Memory-based Exploration agent):</p>
<ul>
<li><p>针对所有策略的转换，并行训练Agent57的整个策略系列的价值函数，而不是仅是行为策略的转换？；</p></li>
<li><p>bootstrapping from the online network；</p></li>
<li><p>using high replay ratios</p></li>
</ul></li>
</ul>
<h3 id="总结">总结</h3>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/20/2022-09-20-Autonomous%20Driving%20-%20BEVFormer%20Learning%20Bird%E2%80%99s-Eye-View%20Representation%20from%20Multi-Camera%20Images%20via%20Spatiotemporal%20Transformers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/20/2022-09-20-Autonomous%20Driving%20-%20BEVFormer%20Learning%20Bird%E2%80%99s-Eye-View%20Representation%20from%20Multi-Camera%20Images%20via%20Spatiotemporal%20Transformers/" class="post-title-link" itemprop="url">Autonomous Driving | BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-20 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-20T00:00:00+08:00">2022-09-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="bevformer-learning-birds-eye-view-representation-from-multi-camera-images-via-spatiotemporal-transformers">BEVFormer:
Learning Bird’s-Eye-View Representation from Multi-Camera Images via
Spatiotemporal Transformers</h2>
<p>多相机3D检测的工作。提出了spatial
cross-attention整合空间信息；提出了temporal self-
attention整合历史BEV信息。</p>
<p>代码开源：https://github.com/zhiqi-li/BEVFormer</p>
<h3 id="related-work">Related Work</h3>
<p><strong>deformable attention mechanism:</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220920-1.png" alt="deformable attention mechanism">
<figcaption aria-hidden="true">deformable attention
mechanism</figcaption>
</figure>
<p><strong>Camera-based 3D Perception:</strong></p>
<p>过去的3D object detection 任务和map segmentation
任务是相互独立的。</p>
<ol type="1">
<li><p>predict the 3D bounding boxes based on 2D bounding
boxes.</p></li>
<li><p>Another solution is to transform image features into BEV features
and predict 3D bounding boxes from the top-down view.</p></li>
</ol>
<p>从多相机特征生成BEV图。A straightforward method is converting
perspective view into the BEV through Inverse Perspective Mapping (IPM)
[35, 5]</p>
<h3 id="bevformer">BEVFormer</h3>
<ul>
<li><p>几个特殊的设计：</p>
<ul>
<li><p><strong>BEV queries;</strong></p>
<p>BEV queries are grid-shaped learnable parameters, which is designed
to query features in BEV space from multi-camera views via attention
mechanisms.</p></li>
<li><p><strong>spatial cross-attention</strong> and <strong>temporal
self-attention</strong>;</p>
<p>Spatial cross-attention and temporal self-attention are attention
layers working with BEV queries, which are used to lookup and aggregate
spatial features from multi-camera images as well as temporal features
from history BEV, according to the BEV query.</p></li>
</ul></li>
</ul>
<h4 id="bev-queries">BEV Queries</h4>
<p>We predefine a group of grid-shaped learnable parameters <span class="math display">\[Q\in R^{H\times W \times C}\]</span> as the
queries of BEVFormer, where H, W are the spatial shape of the BEV plane.
To be specific, the query <span class="math display">\[Q_p \in
R^{1\times C}\]</span> located at <span class="math display">\[p = (x,
y)\]</span> of <span class="math display">\[Q\]</span> is responsible
for the corresponding grid cell region in the BEV plane.</p>
<h4 id="spatial-cross-attention">Spatial Cross-Attention</h4>
<p>未来降低高昂的computational cost of vanilla multi-head attention
[42]，本文采用了deformable attention
[56]模型，这是一个资源高效的注意力层，其中每个BEV查询<span class="math display">\[Q^p\]</span>只与它在摄像机视图上感兴趣的区域交互。</p>
<p>spatial cross-attention (SCA)</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220922-1.png" alt="spatial cross-attention">
<figcaption aria-hidden="true">spatial cross-attention</figcaption>
</figure>
<h4 id="temporal-self-attention">Temporal Self-Attention</h4>
<p>temporal self-attention (TSA) layer</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220922-2.png" alt="temporal self-attention">
<figcaption aria-hidden="true">temporal self-attention</figcaption>
</figure>
<h3 id="总结">总结</h3>
<p>后续没仔细看了，整体框架感觉各个模块衔接比较自然流畅，这也是目前最好的自动驾驶视觉感知方案。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/09/05/2022-09-05%20-%20Python%E6%8A%A5%E9%94%99libGL%20error%20MESA-LOADER%20failed%20to%20open%20iris/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/09/05/2022-09-05%20-%20Python%E6%8A%A5%E9%94%99libGL%20error%20MESA-LOADER%20failed%20to%20open%20iris/" class="post-title-link" itemprop="url">Python报错libGL error: MESA-LOADER: failed to open iris</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-09-05 00:00:00" itemprop="dateCreated datePublished" datetime="2022-09-05T00:00:00+08:00">2022-09-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="python报错libgl-error-mesa-loader-failed-to-open-iris">Python报错libGL
error: MESA-LOADER: failed to open iris</h2>
<h3 id="问题背景">1 问题背景</h3>
<p>执行gym-like环境代码时，渲染动画输出时报错无法找到系统显卡驱动（笔记本，核显，Ubuntu），报错信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: iris</span><br><span class="line">libGL error: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: iris</span><br><span class="line">libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: swrast</span><br></pre></td></tr></table></figure>
<p>然而，根据提示，在<code>/usr/lib/x86_64-linux-gnu/dri</code>路径下是可以找<code>iris_dri.so</code>驱动的。</p>
<h3 id="处理办法">2 处理办法</h3>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/538877347">这篇博客</a>提供了一个有效解决方法：</p>
<p>Step 1: 建立一个 /usr/lib/dri/iris_dri.so 的软连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib$ sudo mkdir dri</span><br><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib$ cd dri </span><br><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:/usr/lib/dri$ sudo ln -s /usr/lib/x86_64-linux-gnu/dri/iris_dri.so iris_dri.so</span><br></pre></td></tr></table></figure>
<p>Step 2: 再次python执行代码，报错变为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">libGL error: MESA-LOADER: failed to open iris: /home/pcon/anaconda3/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found (required by /usr/lib/dri/iris_dri.so) (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: iris</span><br><span class="line">libGL error: MESA-LOADER: failed to open iris: /home/pcon/anaconda3/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found (required by /usr/lib/dri/iris_dri.so) (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: iris</span><br><span class="line">libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\$$&#123;ORIGIN&#125;/dri:/usr/lib/dri, suffix _dri)</span><br><span class="line">libGL error: failed to load driver: swrast</span><br></pre></td></tr></table></figure>
<p>这是由于 conda 里的 libstdcxx-ng 版本不够高造成的。</p>
<p>Step 3：执行以下命令查看GLIBCXX版本信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:~/anaconda3$ strings /home/pcon/anaconda3//lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure>
<p>Step 4：升级 conda 里的 libstdcxx-ng (根据<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/538877347">博客</a>)
。（截至2022.09该版本号有效）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:~/anaconda3$ conda install libstdcxx-ng=12.1.0</span><br></pre></td></tr></table></figure>
<p>再次查看版本号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) pcon@pcon-ThinkPad-L14-Gen-2:~/anaconda3$ strings /home/pcon/anaconda3//lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure>
<p>执行Python代码，成功运行！</p>
<p>ref</p>
<p>https://zhuanlan.zhihu.com/p/538877347</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/08/25/2022-08-25-Autonomous%20Driving%20-%20MP3%20A%20Unified%20Model%20to%20Map%20Perceive%20Predict%20and%20Plan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/08/25/2022-08-25-Autonomous%20Driving%20-%20MP3%20A%20Unified%20Model%20to%20Map%20Perceive%20Predict%20and%20Plan/" class="post-title-link" itemprop="url">Autonomous Driving | MP3 A Unified Model to Map Perceive Predict and Plan (Uber ATG 2021)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-08-25 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-25T00:00:00+08:00">2022-08-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="mp3-a-unified-model-to-map-perceive-predict-and-plan-uber-atg-2021">MP3:
A Unified Model to Map, Perceive, Predict and Plan (Uber ATG, 2021)</h2>
<ul>
<li>HD map具有的语义和几何信息使其成为自动驾驶系统的关键部件。但HD
map的成本很高，难扩展，尤其是厘米级精度（centimeter-level
accuracy）的情况下。因此能摆脱HD
Map（地图加载失败、地图老旧等）的算法值得研究。本文提出了一种<strong>end2end</strong>的<strong>不依赖地图</strong>的自动驾驶算法——MP3。</li>
<li>输入为：
<ul>
<li><strong>raw sensor data</strong></li>
<li><strong>high-level command</strong> (e.g., turn left at the
intersection)</li>
</ul></li>
<li>本文的定位为：mapless technology 的自动驾驶</li>
</ul>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li><p>没有HD map的劣势：</p>
<ul>
<li><p>感知不能再依赖“人行道上的行人”、“道路上的车辆”这样的先验信息；</p></li>
<li><p>进行规划的空间变大了</p></li>
</ul></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-1.png" alt="有地图和无地图对比">
<figcaption aria-hidden="true">有地图和无地图对比</figcaption>
</figure>
<ul>
<li>车辆需要把到达抽象成为路口直行（going straight at an
intersection）、左转（turning left）和右转（turning
right）等高阶的行为指令。</li>
<li>大多数的无地图方法模仿专家的驾驶行为（朝向角、加速度），但是没有提供可解释的中间表征（intermediate
interpretable representations），而这可以帮助解释车辆的决策行为
<ul>
<li>End to end learning for self-driving cars. arXiv preprint
arXiv:1604.07316, 2016.</li>
<li>End-to-end driving via conditional imitation learning. In ICRA,
2018.</li>
<li>Urban driving with conditional imitation learning. arXiv preprint
arXiv:1912.00177, 2019.</li>
<li>Lift, splat, shoot: Encoding images from arbitrary camera rigs by
implicitly unprojecting to 3d. In Proceedings of the European Conference
on Computer Vision, 2020.</li>
</ul></li>
<li>这些方法没有结构信息和先验知识，容易受到分布漂移（distributional
shift）的影响
<ul>
<li>A reduction of imitation learning and structured prediction to
no-regret online learning. In Proceedings of the fourteenth
international conference on artificial intelligence and statistics,
pages 627–635, 2011.</li>
</ul></li>
<li>一些使用在线地图的方法（获得道路边界、中心线），要么过度简单（假设了车道是平行的，但这只在高速场景适用），要么难以将静态环境的不确定性纳入运动规划，而运动规划对于降低风险至关重要。[2,
16, 18, 21, 37],
<ul>
<li>Deep multi-sensor lane detection. In IROS, pages 3102–3109. IEEE,
2018.</li>
<li>3d-lanenet: End-to-end 3d multiple lane detection. In Proceedings of
the IEEE International Conference on Computer Vision, pages 2921–2930,
2019.</li>
<li>Gen-lanenet: A generalized and scalable approach for 3d lane
detection. arXiv, pages arXiv–2003, 2020.</li>
<li>Hierarchical recurrent attention networks for structured online
maps. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 3417–3426, 2018.</li>
</ul></li>
</ul>
<h3 id="related-work">2 Related Work</h3>
<h4 id="online-mapping">2.1 Online Mapping:</h4>
<ul>
<li>特点：
<ul>
<li>satellite imagery (卫星图像)</li>
<li>gather dense information (采集车多次经过同一地方)</li>
<li>human-in-the-loop</li>
</ul></li>
<li>predicting map elements online:
<ul>
<li>3d-lanenet: End-to-end 3d multiple lane detection. In Proceedings of
the IEEE International Conference on Computer Vision, pages 2921–2930,
2019.</li>
<li>Gen-lanenet: A generalized and scalable approach for 3d lane
detection. arXiv, pages arXiv–2003, 2020.</li>
</ul></li>
</ul>
<h4 id="perception-and-prediction">2.2 Perception and Prediction</h4>
<ul>
<li><strong>生成轨迹集合</strong> generate a fixed set of trajectories
[6, 8–10, 26, 28, 30, 36, 56]</li>
<li><strong>画出样本特征分布</strong> draw samples to characterize the
distribution
<ul>
<li>Implicit latent variable model for scene-consistent motion
forecasting. arXiv preprint arXiv:2007.12036, 2020.</li>
<li>R2p2: A reparameterized pushforward policy for diverse, precise
generative path forecasting. In ECCV, 2018.</li>
<li>Multiple futures prediction. In Advances in Neural Information
Processing Systems, pages 15398–15408, 2019.</li>
</ul></li>
<li><strong>预测时间占用图</strong> predict temporal occupancy maps
<ul>
<li>Discrete residual flow for probabilistic pedestrian behavior
prediction. arXiv preprint arXiv:1910.08041, 2019.</li>
<li>The garden of forking paths: Towards multi-future trajectory
prediction. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 10508–10518, 2020.</li>
<li>Scene compliant trajectory forecast with agent-centric
spatio-temporal grids. IEEE RA-L, 5(2):2816–2823, 2020.</li>
</ul></li>
<li>这些方法由于涉及了非最大抑制（non-maximum
suppression）和可信度阈值（confidence
thresholding），可能出现不安全的情况</li>
<li>occupancy grids:
<ul>
<li>Motionnet: Joint perception and motion prediction for autonomous
driving based on bird’s eye view maps. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages
11385–11395, 2020.</li>
<li>Learning occupancy grid maps with forward sensor models. Autonomous
robots, 15(2):111–127, 2003.</li>
<li><strong>Perceive, predict, and plan: Safe motion planning through
interpretable semantic representations.</strong> In Proceedings of the
European Conference on Computer Vision (ECCV), 2020.</li>
</ul></li>
</ul>
<h4 id="motion-planning">2.3 Motion Planning</h4>
<ul>
<li>从感知直接输出控制信号 （Driving policy transfer via modularity and
abstraction. arXiv preprint arXiv:1804.09364,
2018.）会面临稳定性和鲁棒性的问题（stability and robustness
issues）（Exploring the limitations of behavior cloning for autonomous
driving. In Proceedings of the IEEE International Conference on Computer
Vision, pages 9329–9338, 2019.）</li>
</ul>
<h3 id="interpretable-mapless-driving">3 Interpretable Mapless
Driving</h3>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-2.png" alt="MP3 predicts probabilistic scene representations that are leveraged in motion planning as interpretable cost functions">
<figcaption aria-hidden="true">MP3 predicts probabilistic scene
representations that are leveraged in motion planning as interpretable
cost functions</figcaption>
</figure>
<h4 id="extracting-geometric-and-semantic-features">3.1 Extracting
Geometric and Semantic Features</h4>
<ul>
<li>The result is a 3D tensor of size <span class="math display">\[(\frac{H}{a},\frac{W}{a},\frac{Z}{a}\cdot T_p
)\]</span>,which is the input to our backbone network.</li>
<li>This network combines ideas from [9, 53] to extract geometric,
semantic and motion information about the scene.</li>
</ul>
<h4 id="interpretable-scene-representations">3.2 Interpretable Scene
Representations</h4>
<ul>
<li>道路先验信息和一些可解释的知识，使用 <code>online map</code>
表示</li>
<li>动态目标的位置、速度信息，使用 <code>dynamic occupancy field</code>
表示（the dynamic objects position and velocity into the future,
captured in our dynamic occupancy field）</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-3.png" alt="Interpretable Scene representations">
<figcaption aria-hidden="true">Interpretable Scene
representations</figcaption>
</figure>
<ul>
<li>具体而言，两种表征信息包括：</li>
</ul>
<p><strong>Online map representation:</strong></p>
<ul>
<li>Drivable area：以道路边缘为界的可行驶区域；</li>
<li>Reachable
lanes：可用车道是SDV在不违反任何交通规则的情况下可以到达的运动路径的子集。规划轨迹时，我们希望SDV靠近这些可到达的车道，并按照它们的方向行驶。因此，对于地平面中的每个像素，我们预测到最近的可到达车道中心线的无符号距离，在10米处截断，以及最近的可到达车道中心线分段的角度。</li>
<li>Intersection：被交通信号等或者交通标志控制的路段，需要根据信号灯或者标志按交通规定行驶；</li>
</ul>
<p><strong>Dynamic occupancy field:</strong></p>
<p>现有的行为预测算法包括不安全的离散决策unsafe discrete decisions such
as confidence thresholding and non-maximum suppression (NMS)</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220826-4.png" alt="The motion field warps the occupancy over time">
<figcaption aria-hidden="true">The motion field warps the occupancy over
time</figcaption>
</figure>
<ul>
<li>Initial Occupancy：一个BEV网格单元</li>
<li>Temporal Motion Field：a 2D BEV velocity vector (in m/s).</li>
<li><code>Note</code>：车辆、行人和自行车被视为单独的类别，每个类别都有自己的占用流。</li>
</ul>
<p><strong>Probabilistic Model:</strong></p>
<p>online Map 分为以下几个通道：</p>
<ul>
<li><p>可到达区域<span class="math display">\[M^A_i\]</span></p></li>
<li><p>路口<span class="math display">\[M^I_i\]</span></p></li>
<li><p>到最近车道线的距离。the direction of the closest lane centerline
in the reachable lanes <span class="math display">\[M^{\theta}_i\]</span> as a Von Mises distribution
since it has support between <span class="math display">\[[\pi,\pi]\]</span>.</p></li>
<li><p>可到达车道中线的截断距离变换为拉普拉斯算子。We model the
truncated distance transform to the reachable lanes centerline <span class="math display">\[M^D_i\]</span>​ as a Laplacian, which we
empirically found to yield more accurate results than a
Gaussian</p></li>
</ul>
<p>建模动态物体的occupancy <span class="math display">\[O^c\]</span>,为伯努利随机分布<span class="math display">\[O^c_{t,i}\]</span>，<span class="math display">\[c\in
\{行人，车辆，自行车\}\]</span>（考虑这些物体未来行为的多模态（直走或左转）和不确定性），用<span class="math display">\[K_{t,i}\]</span>建模基于K个BEV运动向量<span class="math display">\[V^c_{t,i,k}\]</span>的行为分类分布</p>
<p>the probability of future occupancy under our probabilistic model, we
first define the probability of occupancy flowing from location <span class="math display">\[i_1\]</span> to location <span class="math display">\[i_2\]</span> between two consecutive time steps t
and t + 1 as follows:</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220829-1.png" alt="the probability of occupancy flowing">
<figcaption aria-hidden="true">the probability of occupancy
flowing</figcaption>
</figure>
<h4 id="motion-planning-1">3.3 Motion Planning</h4>
<p>设计了一个基于采样的轨迹规划器，其根据运动学灵活的生成多种轨迹，然后使用一个learned
scoring function选择轨迹。</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220830-1.png" alt="规划器的轨迹选择方式">
<figcaption aria-hidden="true">规划器的轨迹选择方式</figcaption>
</figure>
<h5 id="trajectory-sampling">3.3.1 Trajectory Sampling</h5>
<p>Search-based optimal motion planning for automated driving. In IROS,
2018</p>
<ul>
<li>根据<span class="math display">\[(v_x,a_x,k_x)\]</span>在专家轨迹数据集中检索专家轨迹，<span class="math display">\[x\]</span>表示当前自车状态，检索出的轨迹有不同的初始速度和朝向。因此使用加速度和转向角来描述轨迹<span class="math display">\[(a,\dot k)_t,t=0,...,T\]</span>，输入到a bicycle
model [38]生成具有连续速度和转向角的轨迹。
<ul>
<li>[38]. The kinematic bicycle model: A consistent model for planning
feasible trajectories for autonomous vehicles? In 2017 IEEE Intelligent
Vehicles Symposium (IV), pages 812–818. IEEE, 2017.</li>
</ul></li>
<li>文献[37]提供了一个忽略自车初始状态的简化的轨迹生成模型。
<ul>
<li>[37]. Lift, splat, shoot: Encoding images from arbitrary camera rigs
by implicitly unprojecting to 3d. In Proceedings of the European
Conference on Computer Vision, 2020.</li>
</ul></li>
</ul>
<h5 id="route-prediction">3.3.2 Route Prediction</h5>
<ul>
<li>由于无地图驾驶没有车道线follow，本文假设遵循command来行驶，指令<span class="math display">\[c = (a, d)\]</span>, where <span class="math display">\[a \in \{keep lane, turn left, turn
right\}\]</span> is a discrete high-level action, and <span class="math display">\[d\]</span> an approximate longitudinal distance
to the
action（行为的纵向距离）（d经过”rasterize”处理），输入给CoordConv[29]
<ul>
<li>An intriguing failing of convolutional neural networks and the
coordconv solution. In Advances in Neural Information Processing
Systems, pages 9605–9616, 2018.</li>
</ul></li>
</ul>
<h5 id="trajectory-scoring">3.3.2 Trajectory Scoring</h5>
<ul>
<li>Routing and Driving on Roads:
该评分函数鼓励车辆行驶在概率图R中概率高的区域</li>
</ul>
<p><span class="math display">\[
f_r(\tau,R)=-m(\tau)\min_{i \in m(\tau)} R_i
\]</span></p>
<p>其中<span class="math display">\[m(\tau)\]</span>是BEV图中和自车轨迹<span class="math display">\[\tau\]</span>重合的格子单元（grid-cells that
overlap with SDV polygon in trajectory <span class="math display">\[\tau\]</span>)</p>
<p>离开车道损失： <span class="math display">\[
f_a(x,M)=\max_{i \in m(x)}[1-P(M_i^A)]
\]</span></p>
<ul>
<li><p>Safety</p></li>
<li><p>Comfort</p>
<p>惩罚jerk和加速度</p></li>
</ul>
<h4 id="learning">3.4. Learning</h4>
<p>两阶段的训练。我们分两个阶段优化我们的驾驶模型。我们首先训练<strong>online
map</strong>、<strong>dynamic occupancy
field</strong>和<strong>routing</strong>。一旦这些被收敛，在第二阶段，我们保持这些部分冻结，并为得分函数的线性组合训练规划器权重。我们发现这种两阶段的培训比端到端的培训更稳定。（We
optimize our driving model in two stages. We first train the online map,
dynamic occupancy field, and routing. Once these are converged, in a
second stage, we keep these parts frozen and train the planner weights
for the linear combination of scoring functions. We found this 2-stage
training empirically more stable than training end-to-end.）</p>
<h3 id="experimental-evaluation">4. Experimental Evaluation</h3>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-1.png" alt="性能指标">
<figcaption aria-hidden="true">性能指标</figcaption>
</figure>
<ul>
<li>Imitation Learning (IL), where the future positions of the SDV are
predicted directly from the scene context features, and is trained using
L2 loss.</li>
<li>Conditional Imitation Learning (CIL) [11], which is similar to IL
but the trajectory is conditioned on the driving command.
<ul>
<li>End-to-end driving via conditional imitation learning. In ICRA,
2018.</li>
</ul></li>
<li>Neural Motion Planner (NMP) [55], where a planning cost-volume as
well as detection and prediction are predicted in a multi-task fashion
from the scene context features, and Trajectory Classification (TC)
[37], where a cost-volume is predicted similar to NMP, but the
trajectory cost is used to create a probability distribution over the
trajectories and is trained by optimizing for the likelihood of the
expert trajectory.
<ul>
<li>Lift, splat, shoot: Encoding images from arbitrary camera rigs by
implicitly unprojecting to 3d. In Proceedings of the European Conference
on Computer Vision, 2020.</li>
<li>End-to-end interpretable neural motion planner. In CVPR, 2019.</li>
</ul></li>
<li>Finally, we extend NMP to consider the high-level command by
learning a separate costing network for each discrete action
(CNMP).</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-2.png" alt="Backbone Network">
<figcaption aria-hidden="true">Backbone Network</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-3.png" alt="Mapping Network">
<figcaption aria-hidden="true">Mapping Network</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-4.png" alt="Perception and Prediction Network">
<figcaption aria-hidden="true">Perception and Prediction
Network</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-5.png" alt="Routing Network">
<figcaption aria-hidden="true">Routing Network</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220901-6.png" alt="Sets of trajectories retrieved from the expert demonstrations.">
<figcaption aria-hidden="true">Sets of trajectories retrieved from the
expert demonstrations.</figcaption>
</figure>
<p>后面还有大量实验情景的展示图。</p>
<h3 id="总结">总结</h3>
<p>比较有想法的一个工作，做得比较细致，但是介绍相对粗略，可以仔细研究。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/29/">29</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Txing</p>
  <div class="site-description" itemprop="description">泛用类人决战型机器人博士</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">229</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/yourname" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Txing</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
