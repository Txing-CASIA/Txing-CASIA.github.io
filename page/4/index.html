<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"txing-casia.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="泛用类人决战型机器人博士">
<meta property="og:type" content="website">
<meta property="og:title" content="Txing">
<meta property="og:url" content="https://txing-casia.github.io/page/4/index.html">
<meta property="og:site_name" content="Txing">
<meta property="og:description" content="泛用类人决战型机器人博士">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Txing">
<meta property="article:tag" content="Txing">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://txing-casia.github.io/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Txing</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Txing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">欢迎来到 | 伽蓝之堂</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/08/01/2022-08-01-Autonomous%20Driving%20-%20DriverGym%20Democratising%20Reinforcement%20Learning%20for%20Autonomous%20Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/08/01/2022-08-01-Autonomous%20Driving%20-%20DriverGym%20Democratising%20Reinforcement%20Learning%20for%20Autonomous%20Driving/" class="post-title-link" itemprop="url">Autonomous Driving | DriverGym Democratising Reinforcement Learning for Autonomous Driving</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-08-01 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-01T00:00:00+08:00">2022-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="drivergym-democratising-reinforcement-learning-for-autonomous-driving">DriverGym:
Democratising Reinforcement Learning for Autonomous Driving</h2>
<ul>
<li>现状：目前缺少open-source platform来用real-world
data训练和高效地验证RL算法。</li>
<li>DriverGym 平台的特点：
<ul>
<li>开源（opensource）</li>
<li>与Gym兼容（OpenAI Gym-compatible environment specifically
tailored）</li>
<li>超过1000小时专家记录数据（more than 1000 hours of expert logged
data）<br>
</li>
<li>灵活的闭环评估协议（flexible closed-loop evaluation protocol）</li>
<li>提供行为克隆baselines（provide behavior cloning baselines using
supervised learning and RL）<br>
</li>
<li>代码：https://lyft.github.io/l5kit/ （已失效）</li>
</ul></li>
<li>环境结构：</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220801-2.png" alt="DriverGym">
<figcaption aria-hidden="true">DriverGym</figcaption>
</figure>
<blockquote>
<p>DriverGym: an open-source gym environment that enables training RL
driving policies on real-world data. The RL policy can access rich
semantic maps to control the ego (<strong>red</strong>). Other agents
(<strong>blue</strong>) can either be simulated from the data logs or
controlled using a dedicated policy pre-trained on real-world data. We
provide an extensible evaluation system (<strong>purple</strong>) with
easily configurable metrics to evaluate the idiosyncrasies of the
trained policies.</p>
</blockquote>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li>自动驾驶开源RL仿真环境的对比</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220801-3.png" alt="自动驾驶开源RL仿真环境的对比">
<figcaption aria-hidden="true">自动驾驶开源RL仿真环境的对比</figcaption>
</figure>
<ul>
<li><p>对仿真平台的几个需求：</p>
<ul>
<li><ol type="1">
<li>易于训练RL策略；be used to easily train RL policies using real-world
logs,</li>
</ol></li>
<li><ol start="2" type="1">
<li>可仿真实际的和反应式的周围智能体行为反应；simulate surrounding agent
behavior that is both realistic and reactive to the ego policy,</li>
</ol></li>
<li><ol start="3" type="1">
<li>可高效评估模型；effectively evaluate the trained models,</li>
</ol></li>
<li><ol start="4" type="1">
<li>设计灵活可调；be flexible in its design,</li>
</ol></li>
<li><ol start="5" type="1">
<li>包容整个相关研究社区；inclusive to the entire research
community,</li>
</ol></li>
</ul></li>
<li><p>使用了最大的公开数据集：Level 5 Prediction Dataset</p>
<ul>
<li>J. Houston, G. Zuidhof, L. Bergamini, Y. Ye, A. Jain, S. Omari, V.
Iglovikov, and P. Ondruska. One thousand and one hours: Self-driving
motion prediction dataset. https://level-5.global/level5/data/,
2020.<br>
</li>
</ul></li>
<li><p>支持反应式的行为仿真</p>
<ul>
<li>Luca Bergamini, Y. Ye, Oliver Scheel, Long Chen, Chih Hu, Luca Del
Pero, Blazej Osinski, Hugo Grimmett, and Peter Ondruska. Simnet:
Learning reactive self-driving simulations from real-world observations.
ArXiv, abs/2105.12332, 2021.</li>
</ul></li>
<li><p>闭环评估系统中提供了自动驾驶相关的评估指标，指标支持扩展和合并，应用于策略的训练</p></li>
<li><p>主要贡献：</p>
<ul>
<li>An open-source and OpenAI gym-compatible environment for autonomous
driving task;</li>
<li>Support for more than 1000 hours of real-world expert data;</li>
<li>Support for logged agents replay or data-driven realistic agent
trajectory simulations;</li>
<li>Configurable and extensible evaluation protocol;</li>
<li>Provide pre-trained models and the corresponding reproducible
training code.</li>
</ul></li>
</ul>
<h3 id="related-work">2 Related Work</h3>
<ul>
<li><strong>赛车仿真环境（Racing simulators）：</strong>
<ul>
<li><strong>TORCS</strong>：提供了受限的驾驶场景
<ul>
<li>E. Espié, Christophe Guionneau, Bernhard Wymann, Christos
Dimitrakakis, Rémi Coulom, and Andrew Sumner. Torcs, the open racing car
simulator. 2005.<br>
</li>
</ul></li>
<li><strong>Highway-Env</strong>：环境与Gym兼容，但缺少交通灯、评估协议和专家数据
<ul>
<li>Edouard Leurent. An environment for autonomous driving
decision-making. https://github.com/eleurent/highway-env, 2018.<br>
</li>
</ul></li>
</ul></li>
<li><strong>交通仿真环境（Traffic simulators）</strong>：
<ul>
<li><strong>CARLA</strong>：支持多变的交通情况训练和测试，但周围车辆使用手写规则（hand-coded
rules），真实性有限。
<ul>
<li>A. Dosovitskiy, G. Ros, Felipe Codevilla, Antonio M. López, and V.
Koltun. Carla: An open urban driving simulator. ArXiv, abs/1711.03938,
2017.<br>
</li>
</ul></li>
<li><strong>SUMO</strong>：支持多变的交通情况训练和测试，但周围车辆使用手写规则（hand-coded
rules），真实性有限。
<ul>
<li>Pablo Alvarez Lopez, Michael Behrisch, Laura Bieker-Walz, Jakob
Erdmann, Yun-Pang Flötteröd, Robert Hilbrich, Leonhard Lücken, Johannes
Rummel, Peter Wagner, and Evamarie Wießner. Microscopic traffic
simulation using sumo. In The 21st IEEE International Conference on
Intelligent Transportation Systems. IEEE, 2018. URL
https://elib.dlr.de/124092/.<br>
</li>
</ul></li>
<li><strong>SMARTS</strong>
：有<code>Social Agent Zoo</code>支持数据驱动周围车辆行为。
<ul>
<li>Ming Zhou, Jun Luo, Julian Villela, Yaodong Yang, David Rusu, Jiayu
Miao, Weinan Zhang, Montgomery Alban, Iman Fadakar, Zheng Chen, Aurora
Chongxi Huang, Ying Wen, Kimia Hassanzadeh, Daniel Graves, Dong Chen,
Zhengbang Zhu, Nhat M. Nguyen, Mohamed Elsayed, Kun Shao, Sanjeevan
Ahilan, Baokuan Zhang, Jiannan Wu, Zhengang Fu, Kasra Rezaee, Peyman
Yadmellat, Mohsen Rohani, Nicolas Perez Nieves, Yihan Ni, Seyedershad
Banijamali, Alexander Cowen Rivers, Zheng Tian, Daniel Palenicek,
Haitham Ammar, Hongbo Zhang, Wulong Liu, Jianye Hao, and Jintao Wang.
Smarts: Scalable multi-agent reinforcement learning training school for
autonomous driving. ArXiv, abs/2010.09776, 2020.<br>
</li>
</ul></li>
<li><strong>CRTS</strong>：提供了logs数据接口，使用64小时的真实驾驶数据（real-world
logs）训练周围车辆的行为。集成在Carla中。
<ul>
<li>Blazej Osinski, Piotr Milos, Adam Jakubowski, Pawel Ziecina, Michal
Martyniak, Christopher Galias, Antonia Breuer, Silviu Homoceanu, and
Henryk Michalewski. Carla real traffic scenarios - novel training ground
and benchmark for autonomous driving. ArXiv, abs/2012.11329, 2020.<br>
</li>
</ul></li>
<li><strong>DriverGym</strong>：支持反应式的agent使用数据驱动模型学习真实世界的数据，并提供了1000小时真实的驾驶记录可用于仿真agent</li>
</ul></li>
</ul>
<h3 id="drivergym">3 DriverGym</h3>
<ul>
<li><p>模型兼容两个流行的框架训练策略：</p>
<ul>
<li><strong>SB3</strong>：<a target="_blank" rel="noopener" href="https://github.com/DLR-RM/stable-baselines3">Stable Baselines3
(SB3)</a>是 PyTorch 中强化学习算法的一组可靠实现。它是<a target="_blank" rel="noopener" href="https://github.com/hill-a/stable-baselines">Stable
Baselines</a>的下一个主要版本。
<ul>
<li>Antonin Raffin, Ashley Hill, Maximilian Ernestus, Adam Gleave, Anssi
Kanervisto, and Noah Dormann. Stable baselines3.
https://github.com/DLR-RM/stable-baselines3, 2019.<br>
</li>
</ul></li>
<li><strong>RLlib</strong>：RLlib是一个开源强化学习库,提供了高度可扩展能力和不同应用的统一的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=API&amp;spm=1001.2101.3001.7020">API</a>。RLlib原生支持Tensorflow，Tensorflow
Eager，以及PyTorch，但其内部与这些框架无关。
<ul>
<li>Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox,
Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, and Ion Stoica.
Rllib: Abstractions for distributed reinforcement learning. In ICML,
2018.</li>
</ul></li>
</ul></li>
<li><p>例子场景：绿线是策略预测的轨迹</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220801-4.png" alt="Visualization of an episode rollout (ego in red, agents in blue) in DriverGym. The policy prediction (green line) is scaled by factor of 10 and shown at 2 second intervals for better viewing">
<figcaption aria-hidden="true">Visualization of an episode rollout (ego
in red, agents in blue) in DriverGym. The policy prediction (green line)
is scaled by factor of 10 and shown at 2 second intervals for better
viewing</figcaption>
</figure></li>
<li><p>action space：行为为 <span class="math display">\[(x; y;
yaw)\]</span> (yaw是朝向)，用于更新ego-agent行为；环境输出 <span class="math display">\[(acceleration; steer)\]</span>
用于计算下一时刻的observation</p></li>
<li><p>reactive agent：允许周围车辆使用两种方式控制：</p>
<ul>
<li>log replay：回放真实世界中收集的数据；</li>
<li>reactive simulation：可使用真实世界数据训练neural-network-based
agent models，用于控制车辆行为</li>
</ul></li>
<li><p>reward：支持不同的自动驾驶评价指标，在每一帧进行评价计算，指标可以整合为奖励函数。</p></li>
</ul>
<h3 id="总结">总结</h3>
<p>整体来看，支持Gym环境大大方便了仿真和调试，一些细节问题由于没有实际使用该环境还不清楚，比如车辆密度、速度、周围车辆的观测质量、轨迹质量等。</p>
<p>本文作者正对更多细粒度场景设计评估方案，例如或绿灯路口重新启动等。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/08/01/2022-08-01-Autonomous%20Driving%20-%20Model-based%20offline%20planning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/08/01/2022-08-01-Autonomous%20Driving%20-%20Model-based%20offline%20planning/" class="post-title-link" itemprop="url">Autonomous Driving | Model-based offline planning</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-08-01 00:00:00" itemprop="dateCreated datePublished" datetime="2022-08-01T00:00:00+08:00">2022-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="model-based-offline-planning">Model-based offline planning</h2>
<ul>
<li>由于成本、安全性等因素，很多情况下不能够直接与系统交互来学习控制策略，因此，只能从记录的log数据中学习控制策略（offline
reinforcement
learning）。本文介绍了一种从log数据中学到超越成圣log数据的原策略的新策略的方法，命名为
model-based ofline planning (MBOP)。</li>
</ul>
<h3 id="introduction">Introduction</h3>
<ul>
<li>Offline reinforcement learning包括：
<ul>
<li>model-free方法：
<ul>
<li>Yifan Wu, George Tucker, and Ofir Nachum. Behavior regularized
offline reinforcement learning. CoRR, abs/1911.11361, 2019. URL
http://arxiv.org/abs/1911.11361.<br>
</li>
<li>Xue Bin Peng, Aviral Kumar, Grace Zhang, and Sergey Levine.
Advantage-weighted regression: Simple and scalable off-policy
reinforcement learning. arXiv preprint arXiv:1910.00177, 2019.<br>
</li>
<li>Scott Fujimoto, David Meger, and Doina Precup. Off-policy deep
reinforcement learning without exploration. In International Conference
on Machine Learning, pp. 2052–2062, 2019.<br>
</li>
<li>Ziyu Wang, Alexander Novikov, Konrad Zolna, Josh S Merel, Jost
Tobias Springenberg, Scott E Reed, Bobak Shahriari, Noah Siegel, Caglar
Gulcehre, Nicolas Heess, et al. Critic regularized regression. Advances
in Neural Information Processing Systems, 33, 2020.<br>
</li>
</ul></li>
<li>model-based方法：MOPO,
MoREL学习一个模型，然后用于训练一个无模型策略，这种模式和Dyna模式类似。
<ul>
<li><strong>MOPO</strong>: Tianhe Yu, Garrett Thomas, Lantao Yu, Stefano
Ermon, James Zou, Sergey Levine, Chelsea Finn, and Tengyu Ma. Mopo:
Model-based offline policy optimization. arXiv preprint
arXiv:2005.13239, 2020.<br>
</li>
<li><strong>MoREL</strong>: Rahul Kidambi, Aravind Rajeswaran, Praneeth
Netrapalli, and Thorsten Joachims. Morel: Modelbased offline
reinforcement learning. arXiv preprint arXiv:2005.05951, 2020.<br>
</li>
<li><strong>Dyna</strong>: Richard S Sutton and Andrew G Barto.
Reinforcement learning: An introduction. MIT press, 2018.</li>
</ul></li>
</ul></li>
<li>本文的算法属于model-based，利用model-predictive control (MPC)
，扩展MPPI轨迹规划器，并使用实时规划，产生目标或满足奖励条件的策略。
<ul>
<li>Grady Williams, Nolan Wagener, Brian Goldfain, Paul Drews, James M
Rehg, Byron Boots, and Evangelos A Theodorou. Information theoretic mpc
for model-based reinforcement learning. In 2017 IEEE International
Conference on Robotics and Automation (ICRA), pp. 1714–1721. IEEE,
2017b.</li>
</ul></li>
<li>本文模型MBOP包含三个要素：
<ul>
<li>a learnt <strong>world model</strong>,</li>
<li>a learnt <strong>behavior-cloning policy</strong>,</li>
<li>a learnt <strong>fixed-horizon value-function</strong>.<br>
</li>
</ul></li>
<li>MBOP的核心优势是<strong>数据高效</strong>和<strong>自适应</strong>。只需仅100秒就可以训练出一个和奖励函数、目标状态、基于状态的约束相适应的策略。</li>
<li>MBOP能够对非平稳目标和约束执行zero-shot自适应，但是没有处理非平稳动力学特性的机制。</li>
</ul>
<h3 id="model-based-offline-planning-1">Model-based offline
planning</h3>
<ul>
<li>描述问题为Markov Decision Process (MDP)，<span class="math display">\[(S,A,p,r,\gamma)\]</span>
<ul>
<li><span class="math display">\[s\]</span>是系统状态</li>
<li><span class="math display">\[a\]</span>是行为</li>
<li><span class="math display">\[p(s_{t+1}\mid
s_t,a_t)\]</span>是状态转移概率</li>
<li><span class="math display">\[r(s_t,a_t,s_{t+1})\]</span>是奖励</li>
<li><span class="math display">\[\gamma=1\]</span>是时间折扣系数</li>
</ul></li>
<li>MBOP包括三个函数近似器：
<ul>
<li><span class="math display">\[f_m\]</span>：环境动力学的单步模型，<span class="math display">\[(\hat{r}_t,\hat{s}_{t+1})=f_m(s_t,a_t)\]</span>，本文使用<span class="math display">\[f_m(s_t,a_t)_s\]</span>表示状态预测，使用<span class="math display">\[f_m(s_t,a_t)_r\]</span>表示奖励预测。</li>
<li><span class="math display">\[f_b\]</span>：表示一个行为克隆网络，<span class="math display">\[a_t=f_b(s_t,a_{t-1})\]</span>，被规划算法用来引导轨迹采样的先验。</li>
<li><span class="math display">\[f_R\]</span>：是一个阉割的值函数，提供在状态s中采取行为a后，在固定界限<span class="math display">\[R_H\]</span>上的收益。<span class="math display">\[\hat{R}_H = f_R(s_t,a_{t-1})\]</span></li>
</ul></li>
<li>MBOP-POLICY
<ul>
<li>使用MPC输出每个新状态下的行为（<span class="math display">\[a_t=\pi(s_t)\]</span>）。MPC在每一时间步执行一个固定长度的规划，返回长度为H的轨迹T。选择该轨迹的第一个行为<span class="math display">\[a_t\]</span>并返回。</li>
</ul></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220802-1.png" alt="High-Level MBOP-Policy">
<figcaption aria-hidden="true">High-Level MBOP-Policy</figcaption>
</figure>
<ul>
<li>MBOP-TRAJOPT
<ul>
<li>在PDDM的基础上增加一个策略先验<span class="math display">\[f_b\]</span>和价值预测<span class="math display">\[f_R\]</span></li>
</ul></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220802-2.png" alt="MBOP-Trajopt">
<figcaption aria-hidden="true">MBOP-Trajopt</figcaption>
</figure>
<blockquote>
<p>P.S.：第11行在<span class="math display">\[f_b\]</span>给出的行为上加权了采样轨迹的行为，其含义可能是希望在网络没有收敛时，记录下来的行为也不要偏差太大，都保持在采样轨迹附近，参数<span class="math display">\[\beta\]</span>可被视为学习率。第17行给出多条轨迹中奖励最大的作为输出（re-weighting）</p>
</blockquote>
<h3 id="experimental-results">Experimental results</h3>
<ul>
<li><p>首先，在非常少的数据中心训练，其次，再迁移到基于相同系统动力学的两种novel
tasks中：</p>
<ul>
<li><strong>goal-conditioned tasks</strong> (that ignore the original
reward function)<br>
</li>
<li><strong>constrained tasks</strong> (that require optimising for the
original reward under some state constraint)</li>
</ul></li>
<li><p>使用的数据集RL Unplugged (RLU) 和 D4RL</p>
<ul>
<li><strong>RL Unplugged (RLU)</strong>：Caglar Gulcehre, Ziyu Wang,
Alexander Novikov, Tom Le Paine, Sergio Gomez Colmenarejo, Kon- ´rad
Zolna, Rishabh Agarwal, Josh Merel, Daniel Mankowitz, Cosmin Paduraru,
et al. Rl unplugged: Benchmarks for offline reinforcement learning.
arXiv preprint arXiv:2006.13888, 2020.
<ul>
<li>cartpole-swingup</li>
<li>walker</li>
<li>quadruped</li>
</ul></li>
<li><strong>D4RL</strong>：Justin Fu, Aviral Kumar, Ofir Nachum, George
Tucker, and Sergey Levine. D4rl: Datasets for deep data-driven
reinforcement learning. arXiv preprint arXiv:2004.07219, 2020.
<ul>
<li>halfcheetah</li>
<li>hopper</li>
<li>walker2d</li>
<li>Adroit</li>
</ul></li>
</ul></li>
<li><p>对于 RLU 中的 Quadruped 和 Walker
任务，由于数据集中性能高方差，在训练 <span class="math display">\[f_b\]</span> 和 <span class="math display">\[f_R\]</span>
的过程中，通过设定阈值，舍弃了性能不好的数据。 使用未过滤的数据来训练
<span class="math display">\[f_s\]</span></p></li>
<li><p>对于所有的数据集，90%用于训练，10%用于测试验证</p></li>
<li><p>性能：For the RLU datasets (Fig. 1), we observe that MBOP is able
to find a near-optimal policy on most dataset sizes in Cartpole and
Quadruped with as little as <strong>5000 steps</strong>, which
corresponds to <strong>5 episodes</strong>, or approximately 50 seconds
on Cartpole and 100 seconds on Quadruped. On the Walker datasets MBOP
requires 23 episodes (approx. 10 minutes) before it finds a reasonable
policy, and with sufficient data converges to a score of 900 which is
near optimal. On most tasks, MBOP is able to generate a policy
significantly better than the behavior data as well as the the BC
prior.</p></li>
<li><p>MBOP模型容易适应新的目标函数，例如添加新的子目标函数<span class="math display">\[R&#39;_n\]</span>时， <span class="math display">\[
R&#39;_n = \sum_t f_{obj}(s_t)
\]</span> 其中，<span class="math display">\[f_{obj}\]</span>是用户自定义的目标函数。只需要将轨迹更新规则改为：
<span class="math display">\[
T_t=\frac{\sum_{n=1}^N e^{kR_n+k_{obj}R&#39;_n}A_{n,t}}{\sum_{n=1}^N
e^{kR_n+k_{obj}R&#39;_n}}
\]</span></p></li>
<li><p>为了验证上述模型的适应能力，进行了两个实验：</p>
<ul>
<li><strong>goal-conditioned control</strong>（忽略原始奖励，<span class="math display">\[k=0\]</span>，学习新奖励）</li>
<li><strong>constrained control</strong>（增加了state-based
constraint，然后探索合适的 <span class="math display">\[k\]</span> 和
<span class="math display">\[k_{obj}\]</span> ）</li>
</ul></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220802-3.png" alt="ZERO-SHOT TASK ADAPTATION">
<figcaption aria-hidden="true">ZERO-SHOT TASK ADAPTATION</figcaption>
</figure>
<h3 id="总结">总结</h3>
<p>MBOP为策略生成提供了一种易于实施、数据高效、稳定且灵活的算法。</p>
<p>由于使用了在线规划，使其能够应对变化的目标、成本和环境限制。</p>
<p>但是算法没有在更复杂的场景和约束条件下测试，因此适用范围和效果还缺少验证。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/23/2022-07-23-Autonomous%20Driving%20-%20A%20Review%20of%20Motion%20Planning%20for%20Highway%20Autonomous%20Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/23/2022-07-23-Autonomous%20Driving%20-%20A%20Review%20of%20Motion%20Planning%20for%20Highway%20Autonomous%20Driving/" class="post-title-link" itemprop="url">Autonomous Driving | A Review of Motion Planning for Highway Autonomous Driving</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-23 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-23T00:00:00+08:00">2022-07-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="a-review-of-motion-planning-for-highway-autonomous-driving">A
Review of Motion Planning for Highway Autonomous Driving</h2>
<ul>
<li>高速路具有路径高速（high speed）、路径曲率小（small curvature
roads）、规则具体（specific driver rules）的几项特点。</li>
<li>主要面临的问题：变道（Lane change），避障（obstacle
avoidance），跟车（car following）合并道路（merging）</li>
</ul>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li><p>automakers now try to personalize Advanced Driving Assistance
Systems (ADAS) to the driver’s style [7].</p>
<ul>
<li>[7]. M. Hasenjager and H. Wersing, “Personalization in advanced
driver "assistance systems and autonomous vehicles: A review," in IEEE
Int. Conf. on Intelligent Transportation Systems (ITSC), 2017.</li>
</ul></li>
<li><p>现有的一些辅助技术：</p>
<ul>
<li>巡航控制中的纵向合/横向舒适度和安全性（longitudinal and lateral
comfort and security with the Cruise Control (CC)）</li>
<li>智能速度自适应（Intelligent Speed Adaptation (ISA)）</li>
<li>道路保持辅助（Lane Keeping Assist (LKA)）</li>
<li>离道警报（Lane Departure Warning (LDW)）</li>
</ul></li>
<li><p>自动驾驶分类标准：（With such an evolution in the automotive
field, the Society of Automotive Engineers (SAE) published a standard
classification for autonomous vehicles with a 6-level system, from 0 (no
control but active safety systems) to 5 (no human intervention for
driving) [10]）</p>
<ul>
<li>SAE International J3016, accessed 2018-11-03. [Online]. Available:
https://www.sae.org/standards/content/j3016 201401/<br>
</li>
</ul></li>
<li><p>2007 DARPA城市挑战赛：since the Defense Advanced Research
Projects Agency (DARPA) organized autonomous vehicle competitions in
2004, 2005, and 2007, and thanks to new technologies, autonomous
functions are evolving quickly and treat more complex scenarios in real
environments. The 11 finalist teams of the DARPA Urban Challenge 2007
[11] succeeded in navigating through a city environment.</p></li>
<li><p>Furthermore, highways seem to be the first environment where
drivers would be confident driving in a fully autonomous mode
[26]</p></li>
</ul>
<h3 id="considerations-for-highway-motion-planning">2 Considerations for
highway motion planning</h3>
<h4 id="a.-terminology">A. Terminology</h4>
<ul>
<li><p><strong>ego
vehicle</strong>表示被掌控（mastered）并装备传感器（sensors-equipped）的车辆</p></li>
<li><p><strong>obstacles
vehicle</strong>表示其它车辆，都被视为障碍物。</p></li>
<li><p>车辆的states包括：</p>
<ul>
<li>position</li>
<li>orientation</li>
<li>and their</li>
<li>time derivatives (position, speed, and acceleration, linear and
angular)</li>
</ul></li>
<li><p>The <strong>geometric state space</strong> is called the
<strong>configuration space</strong></p></li>
<li><p>The <strong>evolution space</strong> identifies the
<strong>configuration space-time</strong> in which the ego vehicle can
navigate.</p></li>
<li><p>configuration 和 evolution 空间被分为三个子空间：</p>
<ul>
<li>the <strong>collision space</strong>, in which the ego vehicle
collides with obstacles;</li>
<li>the <strong>uncertain space</strong>, in which there exists a
probability for the ego vehicle to be in collision;</li>
<li>the <strong>free space</strong>, in which there is no
collision.<br>
</li>
<li><strong>free-space</strong> (spatial geometric zones)</li>
<li><strong>path</strong> (sequence of spacerelated states in the free
space, i.e. geometric waypoints)</li>
<li><strong>trajectory</strong> (sequence of spatiotemporal states in
the free space, i.e. time-varying waypoints)<br>
</li>
<li><strong>maneuver</strong> (predefined motion, considered as a
subspace of paths or trajectories, i.e. motion primitives)<br>
</li>
<li><strong>generation</strong>, which builds sequences of paths,
trajectories, maneuvers, or actions<br>
</li>
<li><strong>planning</strong>, meaning the selection of one sequence
among the generated motions<br>
</li>
<li><strong>prediction horizon</strong> denotes the space or/and time
horizon limit for the simulation of motion</li>
</ul></li>
</ul>
<h4 id="b.-motion-planning-scheme">B. Motion Planning Scheme</h4>
<ul>
<li>分层的自动驾驶算法框架</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220731-1.png" alt="A hierarchical scheme of Autonomous Ground Vehicle systems.">
<figcaption aria-hidden="true">A hierarchical scheme of Autonomous
Ground Vehicle systems.</figcaption>
</figure>
<ul>
<li>行为规划包括：(i) route planning, (ii) prediction, (iii) decision
making, (iv) generation, and (v) deformation.</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220731-2.png" alt="Motion planning functions. Motion planning acts as a global, local, and reactive motion strategy.">
<figcaption aria-hidden="true">Motion planning functions. Motion
planning acts as a global, local, and reactive motion
strategy.</figcaption>
</figure>
<p>其中，decision making, generation, and
deformation是核心。参考[32][33]两篇文章，总结的方法如下：</p>
<ul>
<li><p><strong>A high-level predictive planning</strong> built around
three objectives: risk evaluation, criteria minimization, and constraint
ubmission (see II-D). Those are used for decision making (iii), i.e. to
select the best solution out of the candidates’ generation (iv). One
either generates a set of motions and then makes a decision on the
behavior motion, or, defines the behavior to adopt and then fits a set
of motions. This high-level stage benefits from a longer predicted
motion but is time-consuming.</p></li>
<li><p><strong>A low-level reactive planning</strong> deforming the
generated motion from the high-level planning according to a reactive
approach, i.e. the deformation function (v). This acts on a shorter
range of actions and thus has faster computation.</p></li>
</ul>
<p>[32]. L. Claussmann, A. Carvalho, and G. Schildbach, “A path planner
for autonomous driving on highways using a human mimicry approach with
binary decision diagrams,” in IEEE European Control Conference (ECC),
2015. [33]. X. Li, Z. Sun, Q. Zhu, and D. Liu, “A unified approach to
local trajectory planning and control for autonomous driving along a
reference path,” in IEEE Int. Conf. on Mechatronics and Automation
(ICMA), 2014.</p>
<ul>
<li>空间和时间约束：</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220731-3.png" alt="Motion planning functions. Motion planning acts as a global, local, and reactive motion strategy.">
<figcaption aria-hidden="true">Motion planning functions. Motion
planning acts as a global, local, and reactive motion
strategy.</figcaption>
</figure>
<h4 id="c.-specificities-of-highway-driving">C. Specificities of Highway
Driving</h4>
<ul>
<li><p>特点：</p>
<ul>
<li>单向车流</li>
<li>高速a dynamic speed over 60km/h</li>
<li>道路形状简单：直线道路（straight
lines），回旋曲线道路（clothoids），小曲率的环形道路（circles with small
curvature）</li>
</ul></li>
<li><p>障碍车的行为预测分为以下几个：</p>
<ul>
<li>one-direction</li>
<li>two-lane changes – right or left</li>
<li>and to accelerate, maintain speed, or brake</li>
</ul></li>
<li><p>高速路的一些通常境况：</p>
<ul>
<li><p><strong>Lane keeping</strong></p>
<p>纵向安全的情况下保持期望的速度行驶</p></li>
<li><p><strong>Car following</strong></p>
<p>跟随自己前方的车辆，保持安全距离</p></li>
<li><p><strong>Lane changing</strong></p>
<p>受到方向和障碍物的约束，规划需要保证目标车道由充足的空间和合适的行驶速度</p></li>
<li><p><strong>Lateral-most lane changing</strong></p>
<p>一些情况下的交规要求只能在最左/右的车道行驶，因此agent会一直寻求变道的机会，直到到达目标车道</p></li>
<li><p><strong>Passing</strong></p>
<p>在侧向有障碍物的时候遵守lane keeping或者car
following决策的情况，需要保证侧向的安全距离</p></li>
<li><p><strong>Overtaking</strong></p>
<p>超车上复杂的机动动作，包括变道、pass、变道三个过程</p></li>
<li><p><strong>Merging</strong></p>
<p>两个车道合并为一个车道</p></li>
<li><p><strong>Highway toll</strong></p>
<p>高速收费站，先并入虚拟的车道线，进入收费站，之后再加速驶出，并入实际的车道线</p></li>
<li><p>高速场景特点总结：The main differences between highway, except
for platooning, and city driving consist in a further look-ahead time,
with a stronger focus towards the ahead direction of the road, whereas
city driving involves a closer range but in all directions. The highway
vehicle dynamics is also simpler with lower turn-angle, no reverse, and
less braking/acceleration, but higher and more constant speed. Thus,
even if there are less hazards, the risk due to high speed is stronger.
Moreover, the higher distances imply poorer sensors capacities. Finally,
less traffic insures more stable scenario. The algorithms which consider
all these specificities in real-time will be favored for a practical
application on highways.</p></li>
<li><p>[34]. L. Claussmann, M. Revilloud, S. Glaser, and D. Gruyer, “A
study on ai-based approaches for high-level decision making in highway
autonomous driving,” in IEEE. Int. Conf. on Systems, Man, and
Cybernetics (SMC), 2017.</p></li>
</ul></li>
</ul>
<h4 id="d.-constraints-on-highway-driving">D. Constraints on Highway
Driving</h4>
<ul>
<li><p><strong>硬约束</strong>（hard
constraints）：环境约束、交规、安全约束、避免碰撞。</p></li>
<li><p><strong>软约束</strong>（soft
constraints）：时间/距离/能耗最小化，舒适性最大化等乘坐优化约束。</p></li>
<li><p>其他可行性约束依赖于车辆的运动学限制，即非完整动力学，即车辆在只有两个自由度的三维空间中发展，平滑路径，即轨迹应该可微分且其曲率连续，以及车辆的动力学限制。</p></li>
<li><p>作者在文献[27]中认为，生成运动的质量要求应该为：可行、安全、最优、可用、自适应、高效、渐进和交互（feasible,
safe, optimal, usable, adaptive, efficient, progressive, and
interactive）</p></li>
<li><p>[27]. M. Rodrigues, A. McGordon, G. Gest, and J. Marco, “Adaptive
tactical behaviour planner for autonomous ground vehicle,” in IEEE Int.
Conf. on Control, 2016.</p></li>
</ul>
<h3 id="state-of-the-art">3 State of the art</h3>
<ul>
<li><p>运动规划包含了5个方面：</p></li>
<li><ol type="i">
<li>state estimation</li>
</ol></li>
<li><ol start="2" type="i">
<li>time evolution</li>
</ol></li>
<li><ol start="3" type="i">
<li>actions planning</li>
</ol></li>
<li><ol start="4" type="i">
<li>criteria optimization</li>
</ol></li>
<li><ol start="22" type="a">
<li>compliance with constraints</li>
</ol></li>
<li><p>一个争论：是否要区分驾驶模式（distinguishing and not
distinguishing the driving
modes），不同模式下使用不同的数据进行学习。</p></li>
<li><p><strong>分类1：空间构造算法</strong>（Space Configuration）</p>
<ul>
<li><p>总述：sampling points, connected cells, and
lattice这些方法的核心思想在于：（1）对进化空间进行采样或离散化；（2）排除与障碍物冲突或不可行的点、单元或网格；（3）将这些空间分解作为自由空间约束发送，或者用寻路算法(见III-B2)或曲线规划器(见III-B4)求解结果空间配置，以直接将路点、连接单元集或点阵集发送到控制块。</p></li>
<li><p>Sampling-Based Decomposition：</p>
<ul>
<li>Probabilistic RoadMap (PRM) [41]（The most popular random
method），配合Dijkstra算法[42]，先选择路径点，再分配速度曲线</li>
<li>spatiotemporal sampling points predictive
algorithm[43]，采样5维的车辆状态点（车的位置、速度、角度、到达时间），考虑空间分辨率的因素，还可以结合自适应分辨率采样方法[44]</li>
</ul></li>
<li><p>Connected Cells
Decomposition：网格化道路，赋予格子随机权重，然后避障寻路，该方法的缺点在于要求大的记忆容量、较高的计算速度、具有移动障碍物的虚假指示性占领，以及随空间和时间变化的分辨率。</p>
<p>依据不同的速度和形状，障碍物通常表示为凸多边形（convex polygons）
、矩形、 三角形、圆形、椭圆形。</p>
<ul>
<li><strong>非基于障碍物表征的方法</strong>，格子组织可以离线觉得在线填充，网格可以快速获得但没有使用环境特性。eg：exact
decomposition（正在淘汰）</li>
<li><strong>基于障碍物表征的方法</strong>，考虑动态变化的环境，建立在线的网格，更加方便计算和重规划。</li>
</ul></li>
<li><p>Lattice Representation（晶格表征）构建reachability graph of
maneuvers，多用于predictive planning。calculated offline for a quick
replanning [76]. Unfortunately, their application to reactive planning
is mostly limited due to the fixed structure.</p>
<p>经典的晶格表征算法基于maximum turn strategy [13,
76]，只变化车的角度，调整路径。引入速度后的改进方法curvature velocity
method[77],[72], [78]
。方法的缺点在于需要预先定义的运动集，以及高密度的运动图。</p></li>
</ul></li>
<li><p><strong>分类2：路径搜索算法</strong>（Pathfinding
Algorithms）</p>
<p>这类算法属于图论中的一部分，代表算法为Dijkstra and
A*等，主要问题在于图的尺寸和复杂度，以及进一步的动态环境的处理上，总之这些方法不是太适应高速的环境条件。</p></li>
<li><p><strong>分类3：吸引力和排斥力</strong>（Attractive and Repulsive
Forces）</p>
<p>目的地是吸引力，障碍物产生排斥力，由此构建引力图产生规划的轨迹。其优点是方便适应动态的环境。其问题在于局部最优和震荡现象。</p>
<p>Virtual Force Field (VFF) [56]</p>
<p>elastic band algorithm [102]</p></li>
<li><p><strong>分类4：参数化和半参数化曲线</strong>（Parametric and
Semi-parametric Curves）</p>
<p>考虑（1）高速路本省就是由简单的曲线构成的；（2）预先定义的曲线几何很容易实施和测试；曲线路径和速度可以解耦考虑。这里介绍两类算法：</p>
<ul>
<li><p><strong>point-free
curves算法</strong>：首先构建运动学上可行的轨迹，作为一组候选解；然后基于点的子类使用曲线来拟合一组选择的路点(采样点或单元)</p>
<p>该方法也可以参考基于晶格的方法，用一些基本曲线构建可能的运动路径，形成“触手”，以加快求解的速度。但是这些简单曲线的二阶导数不连续</p></li>
<li><p><strong>point-based
curves算法</strong>：能很好适应约束环境的几何特征，各种曲线的选择依赖对环境的认知。</p></li>
</ul></li>
<li><p><strong>分类5：数值优化</strong>（Numerical Optimization）</p>
<p>数值优化方法在运动规划中被广泛使用。一类算法简化求解的复杂度，提高效率；一类算法探索数学上的性质，以在受限的空间（restrictive
space）中推断出预测解。对于第二类方法，其基础的算法是the Linear
Programming (LP) （most popular one: Simplex algorithm[81]）</p>
<p>具体的预测上，使用Model Predictive Control (MPC)，Dynamic Programming
(DP)等</p></li>
<li><p><strong>分类6：人工智能方法</strong>（Artificial
Intelligence）</p>
<p>需要复制并模拟司机的推断和学习能力。本文将这些方法分为两类：<strong>cognitive/rational</strong>
and <strong>rules/learning</strong>，– based on [125]’s distinction
between thinking and acting humanly or rationally</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220801-1.png" alt="A map of AI-based algorithms.">
<figcaption aria-hidden="true">A map of AI-based
algorithms.</figcaption>
</figure>
<ul>
<li><p>人工智能基于逻辑的方法（AI Logic-Based Approach）</p>
<p>依赖专家知识库和规则的专家推理系统。主要缺点在于处理循环推理和枚举所有规则</p>
<ul>
<li><p>决策树：不确定性和近似值增加了计算困难，行为必须被解释为安全合法的。</p></li>
<li><p>有限状态机（Finite State Machine (FSM)）：
只能在已知的知识范围内运行，不能在未知的环境中做生成。</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220808-1.png" alt="Illustration of an FSM for highway">
<figcaption aria-hidden="true">Illustration of an FSM for
highway</figcaption>
</figure></li>
<li><p>Bayesian networks：依赖马尔科夫模型的状态转移因果链。The authors
in [50] develop a Markov Decision Process (MDP) on the <strong>choice of
tentacle trajectories</strong>, and the one in [130] for a
<strong>lane-staying or -changing decision.</strong></p>
<ul>
<li>[50]. H. Mouhagir, R. Talj, V. Cherfaoui, F. Aioun, and F.
Guillemard, “Integrating safety distances with trajectory planning by
modifying the occupancy grid for autonomous vehicle navigation,” in IEEE
Int. Conf. on Intelligent Transportation Systems (ITSC), 2016.<br>
</li>
<li>[130]. S. Zhou, Y. Wang, M. Zheng, and M. Tomizuka, “A hierarchical
planning and control framework for structured highway driving,”
IFACPapersOnLine, vol. 50, no. 1, pp. 9101–9107, 2017.</li>
</ul>
<p>POMDP：</p>
<ul>
<li>[131] S. Ulbrich and M. Maurer, “Towards tactical lane change
behavior planning for automated vehicles,” in IEEE Int. Conf. on
Intelligent Transportation Systems (ITSC), 2015.</li>
<li>[132] E. Galceran, A. G. Cunningham, R. M. Eustice, and E. Olson,
“Multipolicy decision-making for autonomous driving via
changepoint-based behavior prediction: Theory and experiment,”
Autonomous Robots, vol. 41, no. 6, pp. 1367–1382, 2017.</li>
<li>[133] N. Li, D. W. Oyler, M. Zhang, Y. Yildiz, I. Kolmanovsky, and
A. R. Girard, “Game theoretic modeling of driver and vehicle
interactions for verification and validation of autonomous vehicle
control systems,” IEEE Trans. on Control Systems Technology, vol. 26,
no. 5, pp. 1782– 1797, 2018.</li>
</ul></li>
<li><p>人工智能启发式算法（AI Heuristic Algorithms）</p>
<p>优势在于相对快速高效，但是具有启发式算法的通病，即陷入局部最优，无法保证得到全局最优。</p>
<ul>
<li>基于Support Vector Machines (SVM)的个性化变道决策：
<ul>
<li>C. Vallon, Z. Ercan, A. Carvalho, and F. Borrelli, “A machine
learning approach for personalized autonomous lane change initiation and
control,” in IEEE Intelligent Vehicles Symposium (IV), 2017.<br>
</li>
</ul></li>
<li>演化算法（Evolutionary
methods）。在高速场景，最优解并不是必须的，演化算法的高计算效率，获得近似次优解，足以满足要求。</li>
</ul></li>
</ul></li>
<li><p>人工智能近似推理（AI Approximate Reasoning）</p>
<p>该方法与logic approach的区别在于其知识是非boolean形式表示的。
方法的优势在于其灵活，可拓展到非确定性数据中。缺点在于缺少可追踪性和系统性的设计方法</p>
<ul>
<li><p>Artificial Neural Networks (ANN)</p>
<p>主要可分为三类方法：supervised, unsupervised, and reinforcement
learning。他们的缺点在于缺少因果解释</p>
<p>使用卷积网络变道</p>
<ul>
<li>E. Rehder, J. Quehl, and C. Stiller, “Driving like a human:
Imitation learning for path planning using convolutional neural
networks,” in IEEE Int. Conf. on Intelligent Robots and Systems (IROS)
Workshops, 2017.</li>
</ul>
<p>multi-goal overtaking maneuvers[144]</p>
<ul>
<li>D. C. K. Ngai and N. H. C. Yung, “A multiple-goal reinforcement
learning method for complex vehicle overtaking maneuvers,” IEEE Trans.
on Intelligent Transportation Systems, vol. 12, no. 2, pp. 509–522,
2011.</li>
</ul>
<p>automated lane change maneuvers[145]</p>
<ul>
<li>P. Wang, C.-Y. Chan, and A. de La Fortelle, “A reinforcement
learning based approach for automated lane change maneuvers,” IEEE
Intelligent Vehicles Symposium (IV), 2018.</li>
</ul></li>
</ul></li>
<li><p>人工智能类人的方法（AI Human-Like Methods）</p>
<p>类人的驾驶模型的完整描述，参考这篇文章</p>
<ul>
<li>D. D. Salvucci, “Modeling driver behavior in a cognitive
architecture,” Human factors, vol. 48, no. 2, pp. 362–380, 2006</li>
</ul>
<p>可以分解为风险、任务和博弈三类：</p>
<ul>
<li><strong>Risk
estimators</strong>：执行可接受风险和目标安全之间的权衡。</li>
<li><strong>Taxonomic models</strong>：场景和状况细分分类。<br>
</li>
<li><strong>Game
theory</strong>：把所有车辆看做agent参与博弈，缺点是假设所有人准守规则，一些文章进行了改进：
<ul>
<li>N. Li, D. W. Oyler, M. Zhang, Y. Yildiz, I. Kolmanovsky, and A. R.
Girard, “Game theoretic modeling of driver and vehicle interactions for
verification and validation of autonomous vehicle control systems,” IEEE
Trans. on Control Systems Technology, vol. 26, no. 5, pp. 1782–1797,
2018.</li>
</ul></li>
</ul>
<p>人工智能类似人类的方法非常适合在高速公路场景中进行决策，由于这种环境的基本规则，司机的行为更容易预测。也易于理解并与驾驶员分享。但目前还没有统一的处理框架。</p></li>
</ul></li>
</ul>
<h3 id="总结">总结</h3>
<p>这篇文章介绍的范围太大，涵盖的研究方向和方法过多，受篇幅限制，讲的东西又很浅显，价值不大。</p>
<p>​</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/23/2022-07-23-%E4%BD%BF%E7%94%A8VSCode%E8%B0%83%E8%AF%95%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84Python%E8%84%9A%E6%9C%AC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/23/2022-07-23-%E4%BD%BF%E7%94%A8VSCode%E8%B0%83%E8%AF%95%E5%B8%A6%E5%8F%82%E6%95%B0%E7%9A%84Python%E8%84%9A%E6%9C%AC/" class="post-title-link" itemprop="url">使用VSCode调试带参数的Python脚本</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-23 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-23T00:00:00+08:00">2022-07-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="使用vscode调试带参数的python脚本">使用VSCode调试带参数的Python脚本</h2>
<h3 id="问题描述">1 问题描述</h3>
<p>linux系统上执行带参数的python程序直接添加-arg
xxx即可。但在VSCode调试模式（Debug）下该执行方式不可行。那么是否有办法在VSCode上调试带参数的python脚本呢？</p>
<p>这里提供三种方案：</p>
<ul>
<li>2.1 方案1 pbd命令的Debug</li>
<li>2.2 方案2 在launch.json中设置参数的Debug</li>
<li>2.3 方案3 终端命令行中写入参数的Debug</li>
</ul>
<h3 id="解决方案">2 解决方案</h3>
<h4 id="方案1-pbd命令的debug">2.1 方案1 pbd命令的Debug</h4>
<p>终端窗口执行命令</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pdb xxx.py</span><br></pre></td></tr></table></figure>
<p>开启Debug模式，在断点处暂停，可输入以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">h：（<span class="built_in">help</span>）帮助</span><br><span class="line">w：（<span class="built_in">where</span>）打印当前执行堆栈</span><br><span class="line">d：（down）执行跳转到在当前堆栈的深一层（个人没觉得有什么用处）</span><br><span class="line">u：（up）执行跳转到当前堆栈的上一层</span><br><span class="line">b：（<span class="built_in">break</span>）添加断点</span><br><span class="line">	b 列出当前所有断点，和断点执行到统计次数</span><br><span class="line">	b line_no：当前脚本的line_no行添加断点</span><br><span class="line">	b filename:line_no：脚本filename的line_no行添加断点</span><br><span class="line">	b <span class="keyword">function</span>：在函数<span class="keyword">function</span>的第一条可执行语句处添加断点</span><br><span class="line">tbreak：（temporary <span class="built_in">break</span>）临时断点</span><br><span class="line">	在第一次执行到这个断点之后，就自动删除这个断点，用法和b一样</span><br><span class="line">cl：（clear）清除断点</span><br><span class="line">	cl 清除所有断点</span><br><span class="line">	cl bpnumber1 bpnumber2… 清除断点号为bpnumber1,bpnumber2…的断点</span><br><span class="line">	cl lineno 清除当前脚本lineno行的断点</span><br><span class="line">	cl filename:line_no 清除脚本filename的line_no行的断点</span><br><span class="line"><span class="built_in">disable</span>：停用断点，参数为bpnumber，和cl的区别是，断点依然存在，只是不启用</span><br><span class="line"><span class="built_in">enable</span>：激活断点，参数为bpnumber</span><br><span class="line">s：（step）执行下一条命令</span><br><span class="line">	如果本句是函数调用，则s会执行到函数的第一句</span><br><span class="line">n：（next）执行下一条语句</span><br><span class="line">	如果本句是函数调用，则执行函数，接着执行当前执行语句的下一条。</span><br><span class="line">r：（<span class="built_in">return</span>）执行当前运行函数到结束</span><br><span class="line">c：（<span class="built_in">continue</span>）继续执行，直到遇到下一条断点</span><br><span class="line">l：（list）列出源码</span><br><span class="line">	l 列出当前执行语句周围11条代码</span><br><span class="line">	l first 列出first行周围11条代码</span><br><span class="line">	l first second 列出first–second范围的代码，如果second&lt;first，second将被解析为行数</span><br><span class="line">a：（args）列出当前执行函数的函数</span><br><span class="line">p expression：（<span class="built_in">print</span>）输出expression的值</span><br><span class="line">pp expression：好看一点的p expression</span><br><span class="line">run：重新启动debug，相当于restart</span><br><span class="line">q：（quit）退出debug</span><br><span class="line">j lineno：（jump）设置下条执行的语句函数</span><br><span class="line">	只能在堆栈的最底层跳转，向后重新执行，向前可直接执行到行号</span><br><span class="line">unt：（until）执行到下一行（跳出循环），或者当前堆栈结束</span><br><span class="line">condition bpnumber conditon，给断点设置条件，当参数condition返回True的时候bpnumber断点有效，否则bpnumber断点无效</span><br></pre></td></tr></table></figure>
<p><strong>Note：</strong>
<code>1：直接输入Enter，会执行上一条命令；</code>
<code>2：输入PDB不认识的命令，PDB会把他当做Python语句在当前环境下执行；</code></p>
<p>但这种方式不依赖VSCode，并且是在命令行中调试，并不方便。</p>
<h4 id="方案2-在launch.json中设置参数的debug">2.2 方案2
在launch.json中设置参数的Debug</h4>
<p><strong>Step1：</strong>VSCode菜单栏-运行-打开配置，出现launch.json文件。</p>
<p><strong>Step2：</strong>在configurations中添加”args”参数形式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">      <span class="string">&quot;version&quot;</span>: <span class="string">&quot;0.2.0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;configurations&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                  <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Python: Current File&quot;</span></span><br><span class="line">                  <span class="string">&quot;type&quot;</span>: <span class="string">&quot;python&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;program&quot;</span>: <span class="string">&quot;<span class="variable">$&#123;file&#125;</span>&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;console&quot;</span>: <span class="string">&quot;integratedTerminal&quot;</span>,</span><br><span class="line">                  <span class="string">&quot;args&quot;</span>: [</span><br><span class="line">                        <span class="string">&quot;arg1&quot;</span>, <span class="string">&quot;xxx&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;arg2&quot;</span>, <span class="string">&quot;xxx&quot;</span>,</span><br><span class="line">                   ]</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>Step3：</strong>添加完成后，设置断点，按F5执行即可开始调试。</p>
<p>该方式需要预先写入参数，在实际项目中参数数量和名称可能常常发生变化，这种方式在调整时还不够灵活，效率不够高。</p>
<h4 id="方案3-终端命令行中写入参数的debug">2.3 方案3
终端命令行中写入参数的Debug</h4>
<p><strong>Step1：</strong>安装debugpy库，<code>pip install debugpy</code></p>
<p><strong>Step2：</strong>打开本地终端，找到一个未占用的端口号。输入<code>netstat -a</code>
State显示为LISTEN即为未占用，记该端口号为xxxx</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">关于State的说明：</span><br><span class="line">- LISTEN: The socket is listening for incoming connections. Foreign address is not relevant for this line</span><br><span class="line">- ESTABLISHED: The socket has an established connection. Foreign address in the address of the remote end point of the socket.</span><br><span class="line">- CLOSE_WAIT: The remote end has shut down, waiting for the socket to close.</span><br></pre></td></tr></table></figure>
<p><strong>Step3：</strong>修改launch.json中内容为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">	&quot;configurations&quot;: [</span><br><span class="line">		&#123;</span><br><span class="line">			&quot;name&quot;: &quot;Python: Attach&quot;,</span><br><span class="line">			&quot;type&quot;: &quot;python&quot;,</span><br><span class="line">			&quot;request&quot;: &quot;attach&quot;,</span><br><span class="line">			&quot;connect&quot;: &#123;</span><br><span class="line">				&quot;host&quot;: &quot;localhost&quot;,</span><br><span class="line">				&quot;port&quot;: xxxx</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，xxxx表示使用的端口号。</p>
<p><strong>Step4：</strong>假设run
该Python脚本的命令为：<code>python xxx.py -arg1 ARG1 -arg2 ARG2</code>。即脚本有两个参数输入。在进行调试之前，在VSCode终端命令行中键入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m debugpy --listen xxxx --wait-for-client xxx.py -arg1 ARG1 -arg2 ARG2</span><br></pre></td></tr></table></figure>
<p>注意这里监听的端口xxxx即为上一步找到的未占用端口（这里输入的端口号需要和launch.json中设置的端口号一致）</p>
<p>执行上述命令，终端处于执行中，没有任何返回。接下来在程序中设置断点，按下F5键，即可进入VSCode的调试模式。调试方式与不带参数的情况相同。</p>
<h3 id="ref">Ref:</h3>
<p>https://blog.csdn.net/weixin_37251044/article/details/107471459</p>
<p>https://www.cnblogs.com/JavicxhloWong/p/14356814.html（重要参考，感谢）</p>
<p>https://blog.csdn.net/qq_37837061/article/details/124561317</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/22/2022-07-22-Network%20Structure%20-%20A%20ConvNet%20for%20the%202020s/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/22/2022-07-22-Network%20Structure%20-%20A%20ConvNet%20for%20the%202020s/" class="post-title-link" itemprop="url">Network Structure | A ConvNet for the 2020s (Facebook, 2022)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-22T00:00:00+08:00">2022-07-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="a-convnet-for-the-2020s">A ConvNet for the 2020s</h2>
<ul>
<li>纯卷积的网络堪比transformer。</li>
</ul>
<p>Vision Transformers (ViTs)
的引入迅速取代了ConvNets，成为最先进的图像分类模型。另一方面，普通的 ViT
在应用于目标检测和语义分割等一般计算机视觉任务时面临困难。分层
Transformers（例如，Swin Transformers）重新引入了几个 ConvNet 先验，使
Transformers
作为通用视觉骨干实际上可行，并在各种视觉任务上表现出卓越的性能。然而，这种混合方法的有效性在很大程度上仍归功于
Transformer
的内在优势，而不是卷积固有的归纳偏差。在这项工作中，我们重新检查了设计空间并测试了纯
ConvNet 所能达到的极限。</p>
<p>我们逐渐将标准 ResNet “现代化”为视觉 Transformer
的设计，并在此过程中发现了导致性能差异的几个关键组件。这一探索的结果是一系列纯
ConvNet 模型，称为 ConvNeXt。ConvNeXts 完全由标准 ConvNet
模块构建，在准确性和可扩展性方面与 Transformer 竞争，实现 87.8% ImageNet
top-1 准确率，在 COCO 检测和 ADE20K 分割方面优于 Swin
Transformers，同时保持标准 ConvNet 的简单性和效率。</p>
<h3 id="introduction">1. Introduction</h3>
<ul>
<li><p>过去的十年视觉认知领域的研究从特征工程转移到了网络结构设计。</p></li>
<li><p>solutions to numerous computer vision tasks in the past decade
depended significantly on a sliding-window, fully- convolutional
paradigm</p></li>
<li><p>The <strong>biggest challenge</strong> is ViT’s global attention
design, which has a <strong>quadratic complexity</strong> with respect
to the input size. This might be acceptable for ImageNet classification,
but quickly becomes intractable with higher-resolution inputs.</p></li>
<li><p><strong>Swin Transformer</strong> [45] is a milestone work in
this direction, demonstrating for the first time that Transformers can
be adopted as a generic vision backbone and achieve state-of-the-art
performance across a range of computer vision tasks beyond image
classification</p>
<ul>
<li>[45]. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang,
Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision
transformer using shifted windows. 2021.</li>
</ul></li>
</ul>
<h3 id="总结">总结</h3>
<p>写作语言非常高级的一篇介绍网络结构的文章，介绍了如何构建超越transformer的纯卷积网络。并在计算机视觉多项任务中取得了成功，包括ImageNet
top-1。文章值得一看，但由于这不是我重点关注方向，不详细介绍了。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/22/2022-07-22-Autonomous%20Driving%20-%20MotionCNN%20A%20Strong%20Baseline%20for%20Motion%20Prediction%20in%20Autonomous%20Driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/22/2022-07-22-Autonomous%20Driving%20-%20MotionCNN%20A%20Strong%20Baseline%20for%20Motion%20Prediction%20in%20Autonomous%20Driving/" class="post-title-link" itemprop="url">Autonomous Driving | MotionCNN: A Strong Baseline for Motion Prediction in Autonomous Driving (2022)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-22 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-22T00:00:00+08:00">2022-07-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="motioncnn-a-strong-baseline-for-motion-prediction-in-autonomous-driving">MotionCNN:
A Strong Baseline for Motion Prediction in Autonomous Driving</h2>
<h3 id="introduction">1 Introduction</h3>
<ul>
<li>Motion prediction
目前仍然是一个困难的任务，本文提出了一个可以进行多模式的行为预测（multimodal
motion prediction）的较强的baseline (based purely on Convolutional
Neural Networks (CNNs)<br>
</li>
<li>算法在 2021 Waymo Open Dataset Motion Prediction Challenge
取得第三名。相关代码见<a target="_blank" rel="noopener" href="https://github.com/kbrodt/waymo-motion-prediction-2021">Github</a></li>
<li>运动预测任务最重要的一些方法：
<ul>
<li>birds-eye-view rasterized scene representations [15, 6, 4, 11, 18,
14]</li>
<li>methods incarnated using graph neural networks [2, 8, 25]</li>
</ul></li>
</ul>
<h3 id="method">2 Method</h3>
<h4 id="rasterization">2.1 Rasterization</h4>
<ul>
<li>栅格化历史轨迹获得标准化的数据输入</li>
<li>agent 始终位于图像中心</li>
<li>agent 速度方向与x轴对齐</li>
</ul>
<h4 id="model">2.2 Model</h4>
<ul>
<li>在ImageNet上预训练</li>
<li>真实的行为难以预测，因此输出K个不同的行为假设</li>
<li>输入：多通道栅格化图像</li>
<li>输出：预测的K条轨迹，并带有可信度<span class="math display">\[c_1,c_2,...,c_k\]</span>，可信度用softmax归一化，满足<span class="math display">\[\sum_k c_k=1\]</span></li>
</ul>
<h4 id="loss-function">2.3 Loss function</h4>
<ul>
<li><p>使用k个高斯分布，网络输出高斯分布的均值，将每个高斯的协方差固定为单位矩阵<span class="math display">\[I\]</span></p></li>
<li><p>损失函数使用混合高斯分布的负的log似然度negative log-likelihood
(NLL)，混合高斯由真实轨迹坐标定义<br>
</p></li>
<li><p>给定ground truth轨迹：<span class="math display">\[X^{gt}=[(x_1,y_1),...,(x_T,y_T)]\]</span></p></li>
<li><p>给定K个预测的假设轨迹：<span class="math display">\[X_k=[(x_{k,1},y_{k,1}),...,(x_{k,T},y_{k,T})],k=1,...,K\]</span></p></li>
<li><p>计算预测高斯混合下真实轨迹的负对数概率，其均值等于预测轨迹，单位矩阵I为协方差:compute
negative log probability of the ground truth trajectory under the
predicted mixture of Gaussians with the means equal to the predicted
trajectories and the identity matrix I as covariance: <span class="math display">\[
L=-\log P(X^{gt})=-\log\sum_k c_k \mathcal{N}(X^{gt};\mu=X_k,\Sigma=I)
\]</span></p></li>
<li><p>损失函数可以进一步分解为1维高斯的乘积： <span class="math display">\[
L=-\log \sum_k c_k\prod
\mathcal{N}(x_t^{gt};x_{k,t},1)\mathcal{N}(y_t^{gt};y_{k,t},1)\\
=-\log \sum_k \exp \bigg(\log(c_k)-\frac{1}{2}\sum_{t=1}^T
(x_t^{gt}-x_{k,t})^2+(y_t^{gt}-y_{k,t})^2 \bigg)
\]</span></p></li>
<li><p>建议的损失函数没有明确地惩罚产生非常接近的轨迹的模型。然而，根据经验，我们没有观察到模式崩溃，因为将所有的概率质量组合到一个模式中会导致更高的风险策略和更高的预测失误损失值。因此，优化建议的损失产生足够的多模态。</p></li>
</ul>
<h4 id="inference">2.4 Inference</h4>
<ul>
<li>为未来轨迹提供了6个假设</li>
</ul>
<h3 id="experiments">3 Experiments</h3>
<h4 id="dataset">3.1 Dataset</h4>
<ul>
<li>Waymo Open Motion Dataset [22, 7]
<ul>
<li>[22]. Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien
Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai,
Benjamin Caine, Vijay Vasudevan, Wei Han, Jiquan Ngiam, Hang Zhao,
Aleksei Timofeev, Scott Ettinger, Maxim Krivokon, Amy Gao, Aditya Joshi,
Sheng Zhao, Shuyang Cheng, Yu Zhang, Jonathon Shlens, Zhifeng Chen, and
Dragomir Anguelov. Scalability in perception for autonomous driving:
Waymo open dataset, 2020. 3, 4<br>
</li>
<li>[7]. Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang
Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles Qi, Yin Zhou, et
al. Large scale interactive motion forecasting for autonomous driving:
The waymo open motion dataset. arXiv preprint arXiv:2104.10133, 2021. 1,
2, 3, 4<br>
</li>
</ul></li>
<li>Waymo数据包括：
<ul>
<li>object trajectories<br>
</li>
<li>3D maps for 103354 segments</li>
<li>Each segment is a 20 seconds recording of an object trajectory at
10Hz<br>
</li>
<li>map data for the area covered by the segment</li>
<li>A single sample comprises 1 second of history and 8 seconds of
future data obtained by breaking the segments into 9-second windows with
5 second overlap<br>
</li>
<li>每个这样的样本包含多达8个标记为“有效”的代理，模型需要预测它们在未来8秒内的位置。Every
such sample contains up to 8 agents marked as ”valid” for which the
model needs to predict their positions for 8 seconds into the
future.</li>
</ul></li>
<li>Rasterisation details
<ul>
<li>栅格尺寸：224 × 224 × (3 + 2T )，<span class="math display">\[T=11\]</span>​是快照（snapshot）数，3是RGB图像的3个通道，包括road
lines, crosswalks, traffic
lights等；每个历史快照通过两个额外通道表示：（1）The mask representing
the location of the target agent. （2）the mask representing all other
agents nearby<br>
</li>
<li>智能体位于坐标<span class="math display">\[[61,112]\]</span>，其速度与图像的X轴对齐</li>
</ul></li>
</ul>
<h4 id="metrics">3.2 Metrics</h4>
<ul>
<li>预测的轨迹点下采样至2Hz。从预测的80个点产生16个2维坐标的子集被用于计算测试和验证度量</li>
<li>最小化Average Displacement Error：<span class="math display">\[minADE=\min_k \frac{1}{T} \mid\mid X^{gt} -X
\mid\mid_2\]</span></li>
<li>最小化Final Displacement Error (FDE): <span class="math display">\[minFDE=\min_k \mid\mid x_T^{gt}- x_T
\mid\mid_2\]</span></li>
<li>Miss Rate(MR) and mean average precision (mAP) in [7]
<ul>
<li>[7]. Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang
Zhao, Sabeek Pradhan, Yuning Chai, Ben Sapp, Charles Qi, Yin Zhou, et
al. Large scale interactive motion forecasting for autonomous driving:
The waymo open motion dataset. arXiv preprint arXiv:2104.10133, 2021. 1,
2, 3, 4</li>
</ul></li>
</ul>
<h4 id="implementation-details">3.3 Implementation details</h4>
<p>Results from the final leaderboard of the Waymo open dataset motion
prediction challenge [1] are presented in Tab. 1. Despite the simplicity
of the proposed approach we secured the 3rd place according to the mAP
metric. Moreover, our model is superior to the other competing methods
according to Min ADE, Min FDE, and Overlap Rate metrics. Note that in
contrast to methods [12, 9], our simple model achieves such impressive
results without any use of advanced deep learning techniques or complex
architectures.</p>
<p>To test a more lightweight architecture, we also trained our model
using ResNet18 [10] as the backbone and evaluated it on the validation
set (see Tab. 1). This architecture is 3x times faster to train than the
one with Xception71 backbone, but it does not reach the same high
performance showing that a sufficiently deep model is necessary for
attaining good results. In Fig. 4 we show plots with train and
validation loss values during training.</p>
<p>In Tab. 2 we also provide more detailed evaluation results for
different object types separately.</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220722-1.png" alt="Quantitative evaluation on test and validation sets of Waymo Open Motion Dataset">
<figcaption aria-hidden="true">Quantitative evaluation on test and
validation sets of Waymo Open Motion Dataset</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220722-2.png" alt="Detailed evaluation of our MotionCNN-Xception71 model on test and validation sets of Waymo Open Motion Dataset">
<figcaption aria-hidden="true">Detailed evaluation of our
MotionCNN-Xception71 model on test and validation sets of Waymo Open
Motion Dataset</figcaption>
</figure>
<h3 id="总结">总结</h3>
<p>作者也承认整个模型在结构和设计上比较简单，但是结果上是取得了waymo比赛的第三名。这是否意味着他们做了更多的工程化调整才取得如此的成绩？</p>
<p>如果follow这项工作，其他人是否也能实现这样的性能是一个问题。</p>
<p>​</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/16/2022-07-16-Autonomous%20Driving%20-%20ChauffeurNet%20Learning%20to%20Drive%20by%20Imitating%20the%20Best%20and%20Synthesizing%20the%20Worst/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/16/2022-07-16-Autonomous%20Driving%20-%20ChauffeurNet%20Learning%20to%20Drive%20by%20Imitating%20the%20Best%20and%20Synthesizing%20the%20Worst/" class="post-title-link" itemprop="url">Autonomous Driving | ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst (Waymo, 2018)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-16 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-16T00:00:00+08:00">2022-07-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="chauffeurnet-learning-to-drive-by-imitating-the-best-and-synthesizing-the-worst">ChauffeurNet:
Learning to Drive by Imitating the Best and Synthesizing the Worst</h2>
<h3 id="introduction">1. Introduction</h3>
<ul>
<li><p>提出通过扰动专家的驾驶数据创建更多有趣的驾驶情景，例如碰撞和off-road等。</p></li>
<li><p>在模仿学习中，并不是模仿所有的数据，而是利imitation
loss惩罚不期望的情况。</p></li>
<li><p>数据：30 million real-world expert driving examples,
corresponding to about 60 days of continual driving<br>
</p></li>
<li><p>由于无论是原始传感器输入还是直接的控制器输出都很难产生扰动，因此在mid-level的输入输出数据上实施扰动。</p></li>
</ul>
<h3 id="related-work">2. Related Work</h3>
<p>Decades-old work on ALVINN (Pomerleau (1989)) showed how a shallow
neural network could follow the road by directly consuming camera and
laser range data. Learning to drive in an end-to-end manner has seen a
resurgence in recent years. Recent work by Chen et al. (2015)
demonstrated a convolutional net to estimate affordances such as
distance to the preceding car that could be used to program a controller
to control the car on the highway. Researchers at NVIDIA (Bojarski et
al. (2016, 2017)) showed how to train an end-to-end deep convolutional
neural network that steers a car by consuming camera input. Xu et al.
(2017) trained a neural network for predicting discrete or continuous
actions also based on camera inputs. Codevilla et al. (2018) also train
a network using camera inputs and conditioned on high-level commands to
output steering and acceleration. Kuefler et al. (2017) use Generative
Adversarial Imitation Learning (GAIL) with simple affordance-style
features as inputs to overcome cascading errors typically present in
behavior cloned policies so that they are more robust to perturbations.
Recent work from Hecker et al. (2018) learns a driving model using
360-degree camera inputs and desired route planner to predict steering
and speed. The CARLA simulator (Dosovitskiy et al. (2017)) has enabled
recent work such as Sauer et al. (2018), which estimates several
affordances from sensor inputs to drive a car in a simulated urban
environment. Using mid-level representations in a spirit similar to our
own, M¨uller et al. (2018) train a system in simulation using CARLA by
training a driving policy from a scene segmentation network to output
high-level control, thereby enabling transfer learning to the real world
using a different segmentation network trained on real data. Pan et al.
(2017) also describes achieving transfer of an agent trained in
simulation to the real world using a learned intermediate scene labeling
representation. Reinforcement learning may also be used in a simulator
to train drivers on difficult interactive tasks such as merging which
require a lot of exploration, as shown in Shalev-Shwartz et al. (2016).
A convolutional network operating on a space-time volume of bird’s
eye-view representations is also employed by Luo et al. (2018); Djuric
et al. (2018); Lee et al. (2017) for tasks like 3D detection, tracking
and motion forecasting. Finally, there exists a large volume of work on
vehicle motion planning outside the machine learning context and Paden
et al. (2016) present a notable survey.</p>
<h3 id="model-architecture">3. Model Architecture</h3>
<h4 id="input-output-representation">3.1 Input Output
Representation</h4>
<ul>
<li>a top-down coordinate system：
<ul>
<li>agent位姿<span class="math display">\[P_t=(x_t,y_t)\]</span></li>
<li>方向角<span class="math display">\[\theta_t\]</span></li>
<li>速度<span class="math display">\[s_t\]</span></li>
<li>图像大小：W × H pixels, <span class="math display">\[\varphi\]</span> meters/pixel<br>
</li>
<li>因此agent只能看见前方的 <span class="math display">\[R_{forward}=(H-v_0)\phi\]</span> 米</li>
</ul></li>
<li>表征内容：
<ul>
<li><ol type="a">
<li>Roadmap:
3通道彩色图片，包含车道线、停止信号、人行道、路边等等。</li>
</ol></li>
<li><ol start="2" type="a">
<li>Traffic
lights：灰度图像的时间序列，其中该序列的每一帧表示在每个过去的时间步交通灯的已知状态。在每一帧中，我们用一个灰度级给每一个车道中心着色，最亮的灰度级代表红灯，中间灰度级代表黄灯，较暗的灰度级代表绿灯或未知灯。</li>
</ol></li>
<li><ol start="3" type="a">
<li>Speed
limit：单通道图像，并且车道中心的颜色与其速度限制成比例对应。</li>
</ol></li>
<li><ol start="4" type="a">
<li>Route：生成的希望行驶的预定路线。</li>
</ol></li>
<li><ol start="5" type="a">
<li>Current agent box：显示agent在当前时间步的完整边界框。</li>
</ol></li>
<li><ol start="6" type="a">
<li>Dynamic objects in the
environment：一个时序的图像序列，展示所有潜在的动态物体。（车辆、自行车、行人等）</li>
</ol></li>
<li><ol start="7" type="a">
<li>Past agent
poses：agent过去的姿态被渲染成一个单一的灰度图像，显示为位置点轨迹。</li>
</ol></li>
</ul></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220716-1.png" alt="Driving model inputs (a-g) and output (h)">
<figcaption aria-hidden="true">Driving model inputs (a-g) and output
(h)</figcaption>
</figure>
<ul>
<li>用<span class="math display">\[I\]</span>表示上述枚举的各种输入，ChauffeurNet模型循环地预测未来的自车姿态，并用绿色点表示。
<span class="math display">\[
P_{t+\delta t} = \text{ChauffeurNet}(I,P_t)
\]</span></li>
</ul>
<h4 id="model-design">3.2 Model Design</h4>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220716-2.png" alt="Training the driving model">
<figcaption aria-hidden="true">Training the driving model</figcaption>
</figure>
<ul>
<li><p><strong>a convolutional feature network
(FeatureNet)：</strong></p>
<ul>
<li>输入：input data</li>
<li>输出：处理后的上下文特征表征（a digested contextual feature
representation）</li>
</ul></li>
<li><p><strong>a recurrent agent network (AgentRNN)：</strong></p>
<ul>
<li><p>输入：处理后的特征（consumed features）</p></li>
<li><p>输出：迭代地预测连续的路径点（iteratively predicts successive
points）以及其它信息</p></li>
<li><p>AgentRNN还将车辆的边界框预测为每个未来时间步的空间热图。（The
AgentRNN also predicts the bounding box of the vehicle as a spatial
heatmap at each future timestep）<br>
</p></li>
<li><p>point <span class="math display">\[P_k\]</span></p></li>
<li><p>the agent bounding box heatmap <span class="math display">\[B_k\]</span><br>
</p></li>
<li><p>memory <span class="math display">\[M_k\]</span></p></li>
<li><p>FeatureNet 输出的特征<span class="math display">\[F\]</span></p></li>
<li><p><span class="math display">\[P_k,B_k =
\text{AgentRNN}(k,F,M_{k-1},B_{k-1})\]</span></p></li>
</ul></li>
<li><p><strong>Road Mask Network：</strong></p>
<ul>
<li><p>输入：feature representation</p></li>
<li><p>输出：预测可行驶的区域（predicts the drivable areas of the field
of view (on-road vs. off-road)）</p></li>
</ul></li>
<li><p><strong>recurrent perception network
(PerceptionRNN)：</strong></p>
<ul>
<li><p>输入：feature representation</p></li>
<li><p>输出：迭代预测空间热图（iteratively predicts a spatial heatmap
(of every other agent in the scene))</p></li>
</ul></li>
</ul>
<h4 id="system-architecture">3.3 System Architecture</h4>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220718-1.png" alt="Software architecture for the end-to-end driving pipeline">
<figcaption aria-hidden="true">Software architecture for the end-to-end
driving pipeline</figcaption>
</figure>
<h3 id="imitating-the-expert">4. Imitating the Expert</h3>
<ul>
<li><p>AgentRNN在每次迭代中预测三个输出：</p>
<ul>
<li>概率分布<span class="math display">\[P_k(x,y)\]</span></li>
<li>预测边界的热图<span class="math display">\[B_k(x,y)\]</span></li>
<li>回归边界朝向输出<span class="math display">\[\theta_k\]</span> (a
regressed box heading output <span class="math display">\[\theta_k\]</span>)</li>
</ul></li>
<li><p>定义上述三个变量响应的损失函数：(上标<span class="math display">\[gt\]</span>表示相应的ground-truth值；<span class="math display">\[H(a,b)\]</span>表示交叉熵函数；<span class="math display">\[P^{gt}_k\]</span>是二值图像，并且只有ground-truth目标坐标取值为1)</p>
<ul>
<li><span class="math display">\[L_p=H(P_k,P^{gt}_k)\]</span></li>
<li><span class="math display">\[L_B=\frac{1}{WH}\sum_x \sum_y
H(B_k(x,y),B_k^{gt}(x,y))\]</span></li>
<li><span class="math display">\[L_{\theta}=\mid\mid \theta_k -
\theta_k^{gt} \mid\mid_1\]</span></li>
</ul></li>
<li><p>精细的位置预测用<span class="math display">\[\delta
P_k^{gt}\]</span>表示，并用<span class="math display">\[L_1\]</span>损失计算误差：</p>
<p><span class="math display">\[L_{p-subpixel} = \mid\mid \delta
P_k-\delta P_k^{gt} \mid\mid_1\]</span></p>
<p><span class="math display">\[L_{speed}=\mid\mid s_k-s_k^{gt}
\mid\mid_1\]</span></p>
<p>其中，<span class="math display">\[\delta P^{gt}_k = P^{gt}_k-\lfloor
P^{gt}_k \rfloor\]</span>是ground-truth位置坐标的小数部分（the
fractional part）</p></li>
</ul>
<h3 id="beyond-pure-imitation">5. Beyond Pure Imitation</h3>
<ul>
<li><p>合成扰动（Synthesizing
Perturbations），路径的起始点和终点不变，晃动中间某个点的位置，幅度是<span class="math display">\[[-0.5,0.5]\]</span>米，扰动的车头朝向角度为<span class="math display">\[[-\pi/3,\pi/3]\]</span>弧度。最后结合扰动点和端点，拟合出一条平滑的轨迹，让车能在干扰之后回到原来的轨迹。</p></li>
<li><p>通过与最大曲率阈值比较，去除生成的一些不切实际的轨迹</p></li>
<li><p>允许生成的轨迹与其它车辆发生碰撞的情况，这些cases可以帮助训练避免这些情况。</p></li>
<li><p>Beyond the Imitation Loss：</p>
<ul>
<li><p><strong>Collision Loss</strong></p>
<p>直接测量预测的智能体边框<span class="math display">\[B_k\]</span>和ground-truth场景中其它目标边框的重叠区域（directly
measures the overlap of the predicted agent box Bk with the ground-truth
boxes of all the scene objects at each timestep） <span class="math display">\[
L_{collosion}=\frac{1}{WH}\sum_x \sum_y B_{k}(x,y)\cdot Obj^{gt}_k (x,y)
\]</span> 其中，<span class="math display">\[B_k\]</span>是输出的预测的智能体边框似然度地图，<span class="math display">\[Obj^{gt}_k\]</span>是一个二值掩码图，其中其它的动态目标用1表示</p></li>
<li><p><strong>On road loss</strong></p>
<p>避免agent冲出道路边界 <span class="math display">\[
L_{onroad}=\frac{1}{WH}\sum_x \sum_y B_k(x,y)\cdot (1-Road^{gt}(x,y))
\]</span></p></li>
<li><p><strong>Geometry loss</strong></p>
<p>不与目标几何位置重叠的区域作为一个惩罚项损失 <span class="math display">\[
L_{geom}=\frac{1}{WH}\sum_x \sum_yB_k(x,y)\cdot(1-Geom^{gt}(x,y))
\]</span></p></li>
<li><p><strong>Auxiliary losses</strong></p>
<p>使用a recurrent perception network PerceptionRNN预测他车轨迹 <span class="math display">\[
L_{objects}=\frac{1}{WH}\sum_x \sum_y H(Obj_k (x,y),obj^{gt}_k(x,y))
\]</span></p></li>
</ul></li>
<li><p>本文使用的损失函数用两组损失组成：模仿损失（imitation
losses）和环境损失（environment losses）：</p>
<ul>
<li>模仿损失：<span class="math display">\[L_{imit}=\{L_p,L_B,L_{\theta},L_{p-subpixel},L_{speed}\}\]</span></li>
<li>环境损失：<span class="math display">\[L_{env}=\{L_{collision},L_{onroad},L_{geom},L_{objects},L_{road}\}\]</span></li>
<li>总损失：<span class="math display">\[L=\omega_{imit}\sum_{l\in
L_{imit}}l +\omega_{env}\sum_{l \in L_{env}} l\]</span></li>
</ul>
<p>模仿损失导致模型模仿专家的演示，而环境损失阻止不期望的行为，例如碰撞。(The
imitation losses cause the model to imitate the expert’s demonstrations,
while the environment losses discourage undesirable behavior such as
collisions.)</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220718-2.png" alt="Visualization of predictions and loss functions on an example input">
<figcaption aria-hidden="true">Visualization of predictions and loss
functions on an example input</figcaption>
</figure></li>
<li><p>参数情况：</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math display">\[T_{scene}\]</span></th>
<th style="text-align: center;"><span class="math display">\[T_{pose}\]</span></th>
<th style="text-align: center;"><span class="math display">\[\delta
t\]</span></th>
<th style="text-align: center;"><span class="math display">\[N\]</span></th>
<th style="text-align: center;"><span class="math display">\[\Delta\]</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.0 s</td>
<td style="text-align: center;">8.0 s</td>
<td style="text-align: center;">0.2 s</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">25 deg</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math display">\[W\]</span></td>
<td style="text-align: center;"><span class="math display">\[H\]</span></td>
<td style="text-align: center;"><span class="math display">\[u_0\]</span></td>
<td style="text-align: center;"><span class="math display">\[v_0\]</span></td>
<td style="text-align: center;"><span class="math display">\[\phi\]</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">400 px</td>
<td style="text-align: center;">400 px</td>
<td style="text-align: center;">200 px</td>
<td style="text-align: center;">320 px</td>
<td style="text-align: center;">0.2 m/px</td>
</tr>
</tbody>
</table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://txing-casia.github.io/2022/07/14/2022-07-14-Autonomous%20Driving%20-%20Exploring%20Imitation%20Learning%20for%20Autonomous%20Driving%20with%20Feedback%20Synthesizer%20and%20Differentiable%20Rasterization%20(2021%20Apollo%206.0)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Txing">
      <meta itemprop="description" content="泛用类人决战型机器人博士">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Txing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/07/14/2022-07-14-Autonomous%20Driving%20-%20Exploring%20Imitation%20Learning%20for%20Autonomous%20Driving%20with%20Feedback%20Synthesizer%20and%20Differentiable%20Rasterization%20(2021%20Apollo%206.0)/" class="post-title-link" itemprop="url">Autonomous Driving | Exploring Imitation Learning for Autonomous Driving with Feedback Synthesizer and Differentiable Rasterization (2021, Apollo 6.0)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-07-14 00:00:00" itemprop="dateCreated datePublished" datetime="2022-07-14T00:00:00+08:00">2022-07-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-25 09:54:15" itemprop="dateModified" datetime="2023-03-25T09:54:15+08:00">2023-03-25</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="exploring-imitation-learning-for-autonomous-driving-with-feedback-synthesizer-and-differentiable-rasterization-2021-apollo-6.0">Exploring
Imitation Learning for Autonomous Driving with Feedback Synthesizer and
Differentiable Rasterization (2021, Apollo 6.0)</h2>
<h3 id="introduction">Introduction</h3>
<ul>
<li><p>our work adopts a <strong>mid-to-mid approach</strong>
(mid2mid允许便利地增加数据，并且通过任务依赖的loss超过单纯地模仿。allows
us to augment data handily and go beyond pure imitation by having
task-specific losses) where our system’s input is constructed by
building a top-down image representation of the environment that
incorporates both static and dynamic information from our <strong>HD
Map</strong> and <strong>perception system</strong>.<br>
</p></li>
<li><p>Following the philosophy of <strong>DAgger</strong> [2], we
introduce a <strong>feedback synthesizer</strong>（反馈合成器）that
generates and perturbs on-policy data based on the current policy. Then
we train the next policy on the aggregate of collected datasets. The
feedback synthesizer addresses the <strong>distributional shift
issue</strong>, thus improving the overall performance shown in Section
IV.</p>
<ul>
<li>[2]. S. Ross, G. Gordon, and D. Bagnell, “A reduction of imitation
learning and structured prediction to no-regret online learning,” in
AISTATS, 2011, pp. 627–635.<br>
</li>
</ul></li>
<li><p>启发本文的文章：</p>
<ul>
<li>V. Blukis, N. Brukhim, A. Bennett, R. Knepper, and Y. Artzi,
“Following high-level navigation instructions on a simulated quadcopter
with imitation learning,” in RSS, June 2018.</li>
<li>M. Bansal, A. Krizhevsky, and A. Ogale, “ChauffeurNet: Learning to
drive by imitating the best and synthesizing the worst,” in RSS,
2019.</li>
<li>A. Buhler, A. Gaidon, A. Cramariuc, R. Ambrus, G. Rosman, and W.
Burgard, “Driving through ghosts: Behavioral cloning with false
positives,” in IROS, 2020.</li>
<li>D. Chen, B. Zhou, V. Koltun, and P. Krahenbuhl, “Learning by
cheating,” in CoRL, 2020, pp. 66–75.<br>
</li>
</ul></li>
<li><p>单纯的模仿学习没有关于任务的明确的重要目标和约束，因此难免会学习到非期望的行为。通过引入task
losses可以控制这些非期望的行为。</p></li>
<li><p>task losses直接映射到输出轨迹到车辆光栅图像中。The task losses
are implemented by directly projecting the output trajectories into
top-down images using a differentiable vehicle rasterizer.</p></li>
<li><p>They（task losses） effectively penalize behaviors, such as
<strong>obstacle collision</strong>（障碍碰撞）, <strong>traffic rule
violation</strong>（违反交规）, and so on, by building losses between
<strong>rasterized images</strong> and <strong>specific object
masks</strong>.</p></li>
<li><p>Inspired by recent works [9], our output trajectories are
produced by a <strong>trajectory decoding module</strong> that includes
an <strong>LSTM</strong> [10] and a <strong>kinematic layer</strong>
that assures our output trajectories’ feasibility. On the whole, these
designs help us avoid using the heavy AgentRNN network in Chauffeurnet
[5], which functions similarly to a Convolutional-LSTM network [11].</p>
<ul>
<li><p>[5]. M. Bansal, A. Krizhevsky, and A. Ogale, “ChauffeurNet:
Learning to drive by imitating the best and synthesizing the worst,” in
RSS, 2019.</p></li>
<li><p>[9]. H. Cui, T. Nguyen, F.-C. Chou, T.-H. Lin, J. Schneider, D.
Bradley, and N. Djuric, “Deep kinematic models for kinematically
feasible vehicle trajectory predictions,” in ICRA, 2020, pp. 10 563–10
569.</p></li>
<li><p>[11]. X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-k. Wong, and
W.-c. Woo, “Convolutional LSTM network: A machine learning approach for
precipitation nowcasting,” in NeurIPS, vol. 28, 2015, pp.
802–810.</p></li>
</ul></li>
<li><p>Moreover, to further improve the performance, similar to recent
works [12], [13], we introduce a <strong>spatial attention
module</strong>（空间注意力机制） in our network design.</p>
<ul>
<li>[12]. S. Hecker, D. Dai, A. Liniger, and L. Van Gool, “Learning
accurate and human-like driving using semantic maps and attention,” in
IROS, 2020, pp. 2346–2353.</li>
<li>[13]. J. Kim and M. Bansal, “Attentional bottleneck: Towards an
interpretable deep driving network,” in CVPR Workshops, 2020.<br>
</li>
</ul></li>
<li><p>为了提高舒适度，提出了可选择的后处理规划器作为看门人，进行高级别的决策引导和组成新的轨迹。we
propose to add an <strong>optional post-processing planner</strong> as a
gatekeeper which manages to interpret them as high-level decision
guidance and composes a new trajectory that offers better
comfort.</p></li>
<li><p>Our models are trained with <strong>400 hours of human driving
data</strong>. We evaluated our system using <strong>70 autonomous
driving test scenarios (ADS)</strong> that are specifically created for
evaluating the fundamental driving capabilities of a self-driving
vehicle.</p></li>
<li><p>We show that our <strong>learning-based planner (M2)</strong>
trained via imitation learning achieves <strong>70.0% ADS</strong>
<strong>pass rate</strong> and can intelligently handle different
challenging scenarios, including <strong>overtaking a dynamic
vehicle</strong>, <strong>stopping for a red traffic light</strong>, and
so on, as shown in Figure 1.</p></li>
</ul>
<h3 id="related-works">Related works</h3>
<ul>
<li><p><strong>Imitation Learning</strong>：</p>
<p>一般遵循end-to-end philosophy，本文采取mid-to-mid
approach提高数据增强便利性和任务依赖的loss</p></li>
<li><p><strong>Loss and Differentiable Rasterization</strong>：</p>
<p>Imitation learning for motion planning typically applies a loss
between <strong>inferred</strong> and <strong>ground truth
trajectories</strong>. Therefore, the ideas of avoiding collisions or
off-road situations are implicit and don’t generalize well.</p>
<p>Wang et al. [8] leverage a differentiable rasterizer, and it allows
gradients to flow from a discriminator to a generator, enhancing a
trajectory prediction network powered by GANs [21].</p>
<p><strong>General-purpose differentiable mesh renderers</strong> [23],
[24] have also been employed to solve other computer vision
tasks.</p></li>
<li><p><strong>Attention</strong>：</p>
<p>by providing spatial attention heatmaps highlighting image areas that
the network attends to in their tasks. In this work, we introduce the
Atrous Spatial Attentional Bottleneck from [13], providing easily
interpretable attention heatmaps while also enhancing the network’s
performance.</p>
<ul>
<li>[13]. J. Kim and M. Bansal, “Attentional bottleneck: Towards an
interpretable deep driving network,” in CVPR Workshops, 2020.</li>
</ul></li>
<li><p><strong>Data Augmentation</strong>：</p>
<p>DAgger及其变体提出通过拥有更多关于代理可能遇到的状态的数据来解决分布转移问题。特别是，他们基于从当前策略推断的动作在每次迭代中采样新状态，让专家代理演示他们在这些新状态下将采取的动作，并在收集的数据集的集合上训练下一个策略。DAgger
[2] and its variants [32], [4], [3] propose to address the
distributional shift issue by having more data with states that the
agent is likely to encounter. In particular, they sample new states at
each iteration based on the actions inferred from the current policy,
let expert agents demonstrate the actions they would take under these
new states, and train the next policy on the aggregate of collected
datasets.</p>
<ul>
<li>S. Ross, G. Gordon, and D. Bagnell, “A reduction of imitation
learning and structured prediction to no-regret online learning,” in
AISTATS, 2011, pp. 627–635.</li>
</ul>
<p>ChauffeurNet引入了一个随机合成器，通过合成轨迹的扰动来增加演示数据。ChauffeurNet
[5] introduces a random synthesizer that augments the demonstration data
by synthesizing perturbations to the trajectories. In this work, we
explore both ideas and propose a feedback synthesizer improving the
overall performance.</p></li>
</ul>
<h3 id="model-architecture">Model Architecture</h3>
<p>B-CNN（branched CNN）</p>
<ul>
<li><p>refence：Zhu X , Bain M . B-CNN: Branch Convolutional Neural
Network for Hierarchical Classification[J]. 2017.</p></li>
<li><p><strong>Model Input</strong>：</p>
<ul>
<li>使用栅格化的多通道鸟瞰图。bird‘s eye view (BEV) representation with
multiple channels by scene rasterization</li>
<li>The image size is W × H with ρ meters per pixel in resolution.</li>
<li>agent汽车的位置永远在图像的中心位置 <span class="math display">\[p_0
= [i_0,j_0]^T\]</span> ，这种图片模式称为ego-centered</li>
<li>模型输入<span class="math display">\[\mathcal{I}\]</span>是多通道图像，不仅包括ego-vehicle、路况信息、还有车辆速度信息<span class="math display">\[v_0\]</span></li>
</ul></li>
<li><p><strong>Model Design</strong>：</p>
<ul>
<li><p>整个模型分为三个部分：</p>
<ul>
<li>A. 一个带空间注意力分支的CNN模型</li>
<li>B. 一个LSTM decoder</li>
<li>C. 一个可微分的光栅化模块（加在LSTM decoder上）</li>
</ul></li>
<li><p><strong>A.</strong> CNN骨架模型使用MobileNetV2
[37]以平衡输出精度和推断速度。输出特征是<span class="math display">\[F_h\]</span>，经过一个MLP（multilayer
perceptron）层之后，输出扁平的特征<span class="math display">\[h_0\]</span>。该特征作为同时作为LSTM
decoder的初始隐藏状态被使用。</p>
<p>为了减轻计算量，主干CNN的中间特征<span class="math display">\[F_I\]</span>传递给空间注意力模块。注意力使用的是Atrous
Spatial Attentional Bottleneck from [13] （J. Kim and M. Bansal,
“Attentional bottleneck: Towards an interpretable deep driving network,”
in CVPR Workshops, 2020）</p></li>
<li><p><strong>B.</strong> LSTM的 cell state <span class="math display">\[c_0\]</span> is initialized by the Glorot
initialization [38]</p>
<p>模型输出是汽车的转向角序列（steering angle）和加速度序列，记为<span class="math display">\[(\delta_{t-1},a_{t-1})\]</span>。</p>
<p>动力学层： <span class="math display">\[
\begin{align}
\begin{cases}
    x_t=v_{t-1}\sin (\phi_{t-1})\Delta t + y_{t-1}\\
    y_t=v_{t-1}\cos (\phi_{t-1})\Delta t + x_{t-1}\\
    \phi_t=v_{t-1}\frac{\tan (\delta_{t-1})}{L} \Delta t + \phi_{t-1}\\
    v_t=a_{t-1}\Delta t + v_{t-1}
\end{cases}
\end{align}
\]</span></p></li>
<li><p><strong>C.</strong> Differentiable
Rasterizer使用三个高斯基函数来描述汽车的形状。</p>
<p>光栅化函数：<span class="math display">\[g_{i,j}(s_t)=\max_{k=1,2,3}
(N(\mu^k,\Sigma^k))\]</span> <span class="math display">\[
\begin{align}
\begin{cases}
\mu^k=\frac{1}{\rho}(x_t^k-x_0)+P_0\\
\Sigma^k=R(\phi_t)^T \text{diag}(\sigma_l,\sigma_{\omega})R(\phi_t)
\end{cases}
\end{align}
\]</span> 其中，<span class="math display">\[(\sigma_l,sigma_{\omega})=(\frac{1}{3}\alpha
l,\alpha \omega)\]</span>，<span class="math display">\[\alpha\]</span>是固定的比例系数，<span class="math display">\[l\]</span>和<span class="math display">\[\omega\]</span>是车辆的长度和宽度。<span class="math display">\[R(\phi_t)\]</span>表示旋转矩阵。</p></li>
</ul></li>
<li><p><strong>Loss：</strong></p>
<p>trajectory imitation loss：<span class="math display">\[L_{imit}=\sum^{N-1}_{t=0}\lambda\mid\mid s_t -
\hat{s}_t\mid\mid_2\]</span></p>
<p>four task losses：</p>
<ul>
<li><p>obstacle collision：<span class="math display">\[L_{obs}=\sum^{N-1}_{t=0}\frac{1}{WH}\sum_i\sum_j
g_{i,j} \tau_{i,j}^{obs}\]</span></p></li>
<li><p>off-route：<span class="math display">\[L_{route}=\sum^{N-1}_{t=0}\frac{1}{WH}\sum_i\sum_j
g_{i,j} \tau_{i,j}^{route}\]</span></p></li>
<li><p>off-road：<span class="math display">\[L_{road}=\sum^{N-1}_{t=0}\frac{1}{WH}\sum_i\sum_j
g_{i,j} \tau_{i,j}^{road}\]</span></p></li>
<li><p>traffic signal violation：<span class="math display">\[L_{signal}=\sum^{N-1}_{t=0}\frac{1}{WH}\sum_i\sum_j
g_{i,j} \tau_{i,j}^{signal}\]</span> 其中，<span class="math display">\[\tau^{obs}\]</span>, <span class="math display">\[\tau^{route}\]</span>, <span class="math display">\[\tau^{road}\]</span>, and <span class="math display">\[\tau^{signal}\]</span> 是响应的二值掩码（binary
masks）</p></li>
<li><p>总的损失函数：</p>
<p><span class="math display">\[L=L_{imit}+\lambda_{task}(L_{obs}+L_{route}+L_{road}+L_{signal})\]</span></p></li>
</ul></li>
</ul>
<h3 id="data-augmentation">Data Augmentation</h3>
<ul>
<li><p><strong>Random
Synthesizer</strong>：随机扰动轨迹，产生off-road和碰撞的场景。起始点和终止点保持不变，扰动中间过程的<strong>一个</strong>点，并平滑路径轨迹，通过对最大曲率进行阈值处理，仅保留真实的扰动轨迹。</p></li>
<li><p><strong>Feedback
Synthesizer</strong>：学习一个驾驶策略帮助生成新的轨迹数据。用上一次迭代的策略<span class="math display">\[\pi_{t-1}\]</span>生成轨迹数据，用于训练策略<span class="math display">\[\pi_t\]</span>。具体算法如下：</p>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220714-1.png" alt="Feedback Synthesizer">
<figcaption aria-hidden="true">Feedback Synthesizer</figcaption>
</figure></li>
<li><p><strong>Post-processing
Planner</strong>：保证舒适和安全。相关实现在 Apollo 6.0
中（https://github.com/ApolloAuto/apollo/tree/master/modules/planning）
<span class="math display">\[
\text{Quadratic Optimization} \leftarrow
\begin{cases}
\text{Safety Bounds}\\
\text{Learning-based Objective}\\
\text{Comfort Constrains}
\end{cases}
\]</span></p></li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li><p><strong>Implementation Details</strong></p>
<p>方形的BEV图（俯瞰图）宽度<span class="math display">\[W\times
H=200\times200\]</span>，<span class="math display">\[\rho=0.2m/pixel\]</span>。ego-vehicle位于图片的<span class="math display">\[i_0=100,j_0=160\]</span>的位置。使用Apollo的感知模块（“Baidu
Apollo open platform,”
http://apollo.auto/）光栅化2秒的历史数据或者预测数据。使用Adam
optimizer，且初始学习率为<span class="math display">\[0.0003\]</span>。</p></li>
<li><p><strong>Dataset and Augmented Data</strong></p>
<ul>
<li><p>400 hours’ driving data demonstrated by human-drivers in southern
San Francisco bay area。</p></li>
<li><p>经过数据预处理后，保留了250k帧作为原始的训练数据<span class="math display">\[D_0\]</span></p></li>
<li><p>利用random synthesizer生成400k帧数据，记为<span class="math display">\[D_r\]</span></p></li>
<li><p>设置feedback steps T = 5，feedback
synthesizer生成465k帧数据，记为<span class="math display">\[D_f\]</span></p></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220714-2.png" alt="不同模型配置的性能对比">
<figcaption aria-hidden="true">不同模型配置的性能对比</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20220714-3.png" alt="offroad,speeding,collision,and failed to arrive性能对比">
<figcaption aria-hidden="true">offroad,speeding,collision,and failed to
arrive性能对比</figcaption>
</figure></li>
<li><p><strong>Evaluation Scenarios</strong></p>
<p>使用Apollo Dreamland simulator。主要包括4类场景：</p>
<ul>
<li><strong>巡航 Cruising</strong>: normal cruising in straight or
curved roads without other traffic participants.</li>
<li><strong>岔道口 Junction</strong>: junction related scenarios
including left or right turns, U-turns, stop before a traffic signal,
etc.</li>
<li><strong>静态交互 Static Interaction</strong>: interaction with
static obstacles, such as overtaking a stopped car.</li>
<li><strong>动态交互 Dynamic Interaction</strong>: interaction with
dynamic obstacles, for example, overtaking a slow vehicle.</li>
</ul></li>
<li><p><strong>Evaluation Metrics</strong></p>
<p>除了通过率和成功率以外，还使用了舒适度评分。舒适度评分是根据自动驾驶状态和人类驾驶状态的相识度计算得到的。</p>
<p>在人驾数据集<span class="math display">\[D_0\]</span>中还包括了角速度和角加加速度<span class="math display">\[(\omega,j)\]</span>，使用这两个数据，可得舒适度评分为：<span class="math display">\[c=\frac{\sum_{i=1}^N P(\omega,j\mid
D_0)}{n}\]</span>。其中，<span class="math display">\[P(\omega,j\mid
D_0)\]</span>表示状态<span class="math display">\[(\omega,j)\]</span>在人驾数据<span class="math display">\[D_0\]</span>中出现的概率，<span class="math display">\[n\]</span>表示帧数。<span class="math display">\[\omega\]</span>和<span class="math display">\[j\]</span>都经过离散化处理（0.1 and
1.0），直接查表读取响应的概率。</p>
<p>agent被要求在时间限制之内到达目的地，同时避免碰撞等事故（出现则判定失败）。</p></li>
<li><p><strong>Runtime Analysis</strong></p>
<p>an Nvidia Titan-V GPU, Intel Core i7-9700K CPU, and 16GB Memory.</p>
<p>The online inference time per frame is <strong>10ms</strong> in
rendering, <strong>22 ms</strong> in model inference, and <strong>15
ms</strong> (optional) in the post-processing planner. Note that our
model inference time is much shorter than the prior work [5]</p></li>
</ul>
<p>模型出现的主要问题是超速、不能到达和碰撞。超速可以通过添加速度损失来解决，不能到达是由于速度过慢，碰撞多是出现了追尾，因此发生被动碰撞。值得注意的是，实验中其它的车辆都是按照既定轨迹运动的，不会避让ego车辆，因此容易出现追尾风险。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/29/">29</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Txing</p>
  <div class="site-description" itemprop="description">泛用类人决战型机器人博士</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">229</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/yourname" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Txing</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
