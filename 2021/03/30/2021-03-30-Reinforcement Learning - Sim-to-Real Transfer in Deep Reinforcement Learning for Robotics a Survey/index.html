<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="泛用人形决战型机器人博士">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
          Reinforcement Learning | Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics a Survey - 伽蓝之堂 | Txing Blog
        
    </title>

    <link rel="canonical" href="https://txing-casia.github.io/2021/03/30/2021-03-30-Reinforcement Learning - Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics a Survey/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/hux-blog.min.css">


    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 6.3.0"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Txing</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    
<!-- Image to hack wechat -->
<!-- <img src="https://txing-casia.github.io/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="{{ site.baseurl }}/{% if page.header-img %}{{ page.header-img }}{% else %}{{ site.header-img }}{% endif %}" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('img/post-bg-py.jpg')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                          <a class="tag" href="/tags/#Reinforcement Learning" title="Reinforcement Learning">Reinforcement Learning</a>
                        
                          <a class="tag" href="/tags/#Transfer Learning" title="Transfer Learning">Transfer Learning</a>
                        
                    </div>
                    <h1>Reinforcement Learning | Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics a Survey</h1>
                    <h2 class="subheading">机器人领域sim-to-real方向的迁移学习综述</h2>
                    <span class="meta">
                        Posted by Txing on
                        2021-03-30
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <h1 id="Sim-to-Real-Transfer-in-Deep-Reinforcement-Learning-for-Robotics-a-Survey"><a href="#Sim-to-Real-Transfer-in-Deep-Reinforcement-Learning-for-Robotics-a-Survey" class="headerlink" title="Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey"></a>Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey</h1><p>论文链接：<a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9308468">https://ieeexplore.ieee.org/document/9308468</a></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><ul>
<li><p>真实的机器人数据难以获得，或者成本代价高，因此需要用仿真环境模拟，降低成本，保证安全性。Owing to the limitations of gathering real-world data, i.e., sample inefficiency and the cost of collecting it, simulation environments are utilized for training the different agents</p>
</li>
<li><p>问题是仿真和真实之间存在差距。Nonetheless, <strong>the gap between the simulated and real worlds</strong> degrades the performance of the policies once the models are transferred into real robots</p>
</li>
<li><p>主要研究方向：</p>
<ul>
<li>域随机化 domain randomization</li>
<li>域适应 domain adaptation</li>
<li>模仿学习 imitation learning</li>
<li>元学习 meta-learning</li>
<li>知识蒸馏 knowledge distillation</li>
</ul>
</li>
<li><p>Moreover, learning with real robots requires the consideration of <strong>potentially dangerous</strong> or <strong>unexpected behaviors in safety-critical applications</strong> [4]</p>
</li>
<li><p><strong>关键问题</strong>：如何通过<strong>转移知识</strong>并相应地<strong>调整策略</strong>，在真实环境中利用基于模拟的训练。how to exploit simulation-based training in real-world settings by transferring the knowledge and adapting the policies accordingly</p>
</li>
<li><p>仿真的设置与真实设置之间有着固有的不匹配。Simulation-based training provides data at low-cost, but involves <strong>inherent mismatches</strong> with real-world settings</p>
</li>
<li><p>一些基于深度学习的相关算法：</p>
<ul>
<li>adversarial attacks on computer vision algorithms [7].</li>
<li>introduce perturbances in the environment [8]</li>
<li>domain randomization [9]</li>
<li>Another key aspect to take into account is that an agent deployed in the real world will potentially be exposed to novel experiences that were not present in the simulations [10]</li>
<li>meta learning [11]</li>
<li>continual learning [12]</li>
<li>更好的仿真引擎 physics engines: Airsim [13], CARLA [14], RotorS [15], [16], and others [17]</li>
</ul>
</li>
<li><p>安全的强化学习这也是一个方向 safe reinforcement learning [4]</p>
</li>
<li><p>几个方向的关系如下图所示：</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/txing-casia/txing-casia.github.io/master/img/20210330-1.png"></p>
<h3 id="A-Deep-Reinforcement-Learning"><a href="#A-Deep-Reinforcement-Learning" class="headerlink" title="A. Deep Reinforcement Learning"></a>A. Deep Reinforcement Learning</h3><ul>
<li>略</li>
</ul>
<h3 id="B-Sim-to-Real-Transfer"><a href="#B-Sim-to-Real-Transfer" class="headerlink" title="B. Sim-to-Real Transfer"></a>B. Sim-to-Real Transfer</h3><ul>
<li>Transferring DRL policies form simulation environments to reality is a necessary step towards more complex robotic systems that have DL-defined controllers.</li>
</ul>
<h3 id="C-Transfer-Learning-and-Domain-Adaptation"><a href="#C-Transfer-Learning-and-Domain-Adaptation" class="headerlink" title="C. Transfer Learning and Domain Adaptation"></a>C. Transfer Learning and Domain Adaptation</h3><ul>
<li><strong>迁移学习</strong>：Transfer learning aims at improving the performance of target learners on <strong>target domains</strong> by transferring the knowledge contained in different but related <strong>source domains</strong> [18]. In this way, transfer learning can reduce the dependence of target domain data when constructing target learners.</li>
<li><strong>域适应</strong>：它指定了当我们有足够的源域标记数据和与目标任务相同的单个任务，但没有或很少目标域数据时的情况。It specifies the situation when we have sufficient source domain labeled data and the same single task as the target task, but without or very few target domain data. In sim-to-real robotics, researchers tend to employ a simulator to train the RL model and then deploy it in the realistic environment, where we should take advantage of the domain adaptation techniques in order to transfer the simulation based model well</li>
</ul>
<h3 id="D-Knowledge-Distillation"><a href="#D-Knowledge-Distillation" class="headerlink" title="D. Knowledge Distillation"></a>D. Knowledge Distillation</h3><ul>
<li>一般用于大型网络，例如使用视觉图像输入的深层网络</li>
<li>使用网络教另一个网络，这样使得两个网络性能差不多，但是学得更快。In these set-ups, the two networks are typically called teacher and student.</li>
</ul>
<h3 id="E-Meta-Reinforcement-Learning"><a href="#E-Meta-Reinforcement-Learning" class="headerlink" title="E. Meta Reinforcement Learning"></a>E. Meta Reinforcement Learning</h3><ul>
<li>通常采用LSTM。MetaRL usually implements an LSTM policy and incorporates the last reward $$r_{t−1}$$ and last action $$a_{t−1}$$ into the current policy observation</li>
</ul>
<h3 id="F-Robust-RL-and-Imitation-Learning"><a href="#F-Robust-RL-and-Imitation-Learning" class="headerlink" title="F. Robust RL and Imitation Learning"></a>F. Robust RL and Imitation Learning</h3><ul>
<li><p>Robust RL [23] was proposed quite early as a new RL paradigm that explicitly takes into account input disturbances as well as modeling errors</p>
</li>
<li><p>It considers a bad, or even adversarial model and tries to maximize the reward as a optimization problem [24], [25].</p>
</li>
<li><p><strong>Imitation learning</strong> proposes to employ expert demonstration or trajectories instead of manually constructing a fixed reward function to train RL agents.</p>
<ul>
<li><strong>behaviour cloning</strong> where an agent learns a mapping from observations to actions given demonstrations [26], [27]</li>
<li><strong>inverse reinforcement learning</strong> where an agent attempts to estimate a reward function that describes the given demonstrations [28].</li>
</ul>
</li>
<li><p>机器人导航任务的方法：</p>
<ul>
<li>curriculum learning [37]</li>
<li>incremental environment complexity [39]</li>
<li>continual learning and policy distillation for multiple tasks [12]</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>即时限定在机器人领域，迁移学习也不是一个很具体的范畴。</p>


                <hr>

                

                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2021/03/30/2021-03-30-Q1721-交换链表中的节点-中等-链表/" data-toggle="tooltip" data-placement="top" title="Q1721-交换链表中的节点-中等-链表">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2021/03/29/2021-03-29-JZOffer 35-复杂链表的复制-中等-链表/" data-toggle="tooltip" data-placement="top" title="JZOffer 35 复杂链表的复制-中等-链表">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                

                

            </div>
    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Reinforcement Learning" title="Reinforcement Learning">Reinforcement Learning</a>
                        
                          <a class="tag" href="/tags/#Transfer Learning" title="Transfer Learning">Transfer Learning</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="https://blog.uomi.moe" target="_blank">驱逐舰患者</a></li>
                    
                        <li><a href="https://m.mepai.me/photographyer/u_5a68085ba15aa.html?tdsourcetag=s_pctim_aiomsg" target="_blank">隐之-INF</a></li>
                    
                </ul>
                
            </div>

        </div>
    </div>
</article>









    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Txing 2023 
                    <br>
                    Theme by <a target="_blank" rel="noopener" href="http://huangxuan.me">Hux</a> 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    Ported by <a target="_blank" rel="noopener" href="http://blog.kaijun.rocks">Kaijun</a> | 
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=kaijun&repo=hexo-theme-huxblog&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://txing-casia.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->




<!-- Baidu Tongji -->


<!-- Side Catalog -->





<!-- Image to hack wechat -->
<img src="https://txing-casia.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
